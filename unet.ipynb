{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "unet.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lkforward/flower/blob/master/unet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PsTeKghC1OuB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "e26927b3-03d7-4af6-bc87-336bb23ecce9"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)\n",
        "\n",
        "!ls"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n",
            "code  gdrive  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-T1l343ofXUY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 742
        },
        "outputId": "01b34eb7-583b-4c02-ab62-89421606f635"
      },
      "source": [
        "!pip install albumentations==0.3.2"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting albumentations==0.3.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ad/34/e1da4fab7282d732a6cef827c7e5fb1efa1f02c3ba1bff4a0ace2daf6639/albumentations-0.3.2.tar.gz (79kB)\n",
            "\r\u001b[K     |████                            | 10kB 16.7MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 20kB 1.7MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 30kB 2.5MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 40kB 1.7MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 51kB 2.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 61kB 2.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 71kB 2.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 81kB 2.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from albumentations==0.3.2) (1.17.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from albumentations==0.3.2) (1.3.2)\n",
            "Collecting opencv-python-headless\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1f/dc/b250f03ab68068033fd2356428c1357431d8ebc6a26405098e0f27c94f7a/opencv_python_headless-4.1.1.26-cp36-cp36m-manylinux1_x86_64.whl (22.1MB)\n",
            "\u001b[K     |████████████████████████████████| 22.1MB 101kB/s \n",
            "\u001b[?25hCollecting imgaug<0.2.7,>=0.2.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ad/2e/748dbb7bb52ec8667098bae9b585f448569ae520031932687761165419a2/imgaug-0.2.6.tar.gz (631kB)\n",
            "\u001b[K     |████████████████████████████████| 634kB 44.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: PyYAML in /usr/local/lib/python3.6/dist-packages (from albumentations==0.3.2) (3.13)\n",
            "Requirement already satisfied: scikit-image>=0.11.0 in /usr/local/lib/python3.6/dist-packages (from imgaug<0.2.7,>=0.2.5->albumentations==0.3.2) (0.15.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from imgaug<0.2.7,>=0.2.5->albumentations==0.3.2) (1.12.0)\n",
            "Requirement already satisfied: imageio>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations==0.3.2) (2.4.1)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations==0.3.2) (3.1.1)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations==0.3.2) (2.4)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations==0.3.2) (1.1.1)\n",
            "Requirement already satisfied: pillow>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations==0.3.2) (4.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations==0.3.2) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations==0.3.2) (1.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations==0.3.2) (2.6.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations==0.3.2) (2.4.5)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=2.0->scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations==0.3.2) (4.4.1)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow>=4.3.0->scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations==0.3.2) (0.46)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations==0.3.2) (41.4.0)\n",
            "Building wheels for collected packages: albumentations, imgaug\n",
            "  Building wheel for albumentations (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for albumentations: filename=albumentations-0.3.2-cp36-none-any.whl size=51063 sha256=d37470f4844d6b30be983bfcc354ff942e3bacf659cdeb805e970cdc9dacdc92\n",
            "  Stored in directory: /root/.cache/pip/wheels/4c/74/a9/b8cfb94bcf1a5d7ea53a6b522bcd372b23b64595b7328e4f3f\n",
            "  Building wheel for imgaug (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for imgaug: filename=imgaug-0.2.6-cp36-none-any.whl size=654020 sha256=37daade52fec8b624f98d020b8a0d11e69c8e140f83f025390756e90007b13a1\n",
            "  Stored in directory: /root/.cache/pip/wheels/97/ec/48/0d25896c417b715af6236dbcef8f0bed136a1a5e52972fc6d0\n",
            "Successfully built albumentations imgaug\n",
            "Installing collected packages: opencv-python-headless, imgaug, albumentations\n",
            "  Found existing installation: imgaug 0.2.9\n",
            "    Uninstalling imgaug-0.2.9:\n",
            "      Successfully uninstalled imgaug-0.2.9\n",
            "  Found existing installation: albumentations 0.1.12\n",
            "    Uninstalling albumentations-0.1.12:\n",
            "      Successfully uninstalled albumentations-0.1.12\n",
            "Successfully installed albumentations-0.3.2 imgaug-0.2.6 opencv-python-headless-4.1.1.26\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OMzxlzg5em5k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader, Dataset\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "import cv2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6FhNtdgWfjFg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "import albumentations as albu\n",
        "from albumentations import torch as AT"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1lflLzVRFKBM",
        "colab_type": "text"
      },
      "source": [
        "# Load the U-Net Model Implementation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9m_DT0iY2W58",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "69b211cc-66ae-46b7-f2b5-393e0a626f4c"
      },
      "source": [
        "# #Clone the code into google drive: \n",
        "\n",
        "# Codebase 1:\n",
        "# !git clone https://github.com/vlievin/Unet.git /content/gdrive/My\\ Drive/kaggle_cloud/code_myunet\n",
        "\n",
        "# Codebase 2:\n",
        "# !git clone https://github.com/lyakaap/Kaggle-Carvana-3rd-Place-Solution.git /content/gdrive/My\\ Drive/kaggle_cloud/code_3rdplace_unet"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into '/content/gdrive/My Drive/kaggle_cloud/code_3rdplace_unet'...\n",
            "remote: Enumerating objects: 57, done.\u001b[K\n",
            "remote: Total 57 (delta 0), reused 0 (delta 0), pack-reused 57\u001b[K\n",
            "Unpacking objects: 100% (57/57), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PYMo3pFQ2hDJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "7accdf32-813a-4e51-d3ba-1c8842dc60c2"
      },
      "source": [
        "# !ln -sfn /content/gdrive/My\\ Drive/kaggle_cloud/code_myunet code\n",
        "# !ln -sfn /content/gdrive/My\\ Drive/kaggle_cloud/code_3rdplace_unet code\n",
        "!ls code"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "losses.py\t    model.py\t      network.png  train.py\n",
            "make_submission.py  model_pytorch.py  README.md\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JnfOMnr62003",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# #If you want to view the code from a pop-up window: \n",
        "# %pycat code/unet.py\n",
        "# %pycat code/model_pytorch.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cV9N-MkH1rRo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# %%writefile code/model_pytorch.py\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class ConvActivation(nn.Module):\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, kernel_size,\n",
        "                 stride=1, padding=1, dilation=1,\n",
        "                 activation=nn.ReLU(inplace=True)):\n",
        "        super(ConvActivation, self).__init__()\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size,\n",
        "                              stride, padding, dilation)\n",
        "        self.activation = activation\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        x = self.activation(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class ConvBNActivation(nn.Module):\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, kernel_size,\n",
        "                 stride=1, padding=1, dilation=1,\n",
        "                 activation=nn.ReLU(inplace=True)):\n",
        "        super(ConvBNActivation, self).__init__()\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size,\n",
        "                              stride, padding, dilation)\n",
        "        self.bn = nn.BatchNorm2d(out_channels)\n",
        "        self.activation = activation\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        x = self.bn(x)\n",
        "        x = self.activation(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class ConvBlock(nn.Module):\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, kernel_size,\n",
        "                 stride=1, padding=1, dilation=1,\n",
        "                 batch_norm=False, activation=nn.ReLU(inplace=True)):\n",
        "        super(ConvBlock, self).__init__()\n",
        "        conv = ConvBNActivation if batch_norm else ConvActivation\n",
        "        self.block = nn.Sequential(\n",
        "            conv(in_channels, out_channels, kernel_size,\n",
        "                 stride, padding, dilation, activation),\n",
        "            conv(out_channels, out_channels, kernel_size,\n",
        "                 stride, padding, dilation, activation)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.block(x)\n",
        "        return out\n",
        "\n",
        "\n",
        "class UpBlockWithSkip(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size,\n",
        "                 stride=1, padding=1, dilation=1, up_mode='deconv',\n",
        "                 batch_norm=False, activation=nn.ReLU(inplace=True)):\n",
        "        assert up_mode in ('deconv', 'biupconv', 'nnupconv')\n",
        "        super(UpBlockWithSkip, self).__init__()\n",
        "\n",
        "        if up_mode == 'deconv':\n",
        "            self.up = nn.ConvTranspose2d(\n",
        "                in_channels, out_channels,\n",
        "                kernel_size=4, stride=2, padding=1)\n",
        "        elif up_mode == 'biupconv':\n",
        "            self.up = nn.Sequential(\n",
        "                nn.Upsample(mode='bilinear', scale_factor=2,\n",
        "                            align_corners=False),\n",
        "                nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
        "            )\n",
        "        elif up_mode == 'nnupconv':\n",
        "            self.up = nn.Sequential(\n",
        "                nn.Upsample(mode='nearest', scale_factor=2,\n",
        "                            align_corners=False),\n",
        "                nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
        "            )\n",
        "\n",
        "        self.conv_block = ConvBlock(\n",
        "            out_channels * 2, out_channels, kernel_size,\n",
        "            stride, padding, dilation, batch_norm, activation)\n",
        "\n",
        "    def forward(self, x, bridge):\n",
        "        up = self.up(x)\n",
        "        out = torch.cat([up, bridge], 1)\n",
        "        out = self.conv_block(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class DilatedUNet(nn.Module):\n",
        "    def __init__(self, in_channels=3, classes=1, depth=3,\n",
        "                 first_channels=44, padding=1,\n",
        "                 bottleneck_depth=6, bottleneck_type='cascade',\n",
        "                 batch_norm=False, up_mode='deconv',\n",
        "                 activation=nn.ReLU(inplace=True)):\n",
        "\n",
        "        assert bottleneck_type in ('cascade', 'parallel')\n",
        "        super(DilatedUNet, self).__init__()\n",
        "\n",
        "        self.depth = depth\n",
        "        self.bottleneck_type = bottleneck_type\n",
        "\n",
        "        conv = ConvBNActivation if batch_norm else ConvActivation\n",
        "\n",
        "        prev_channels = in_channels\n",
        "        self.down_path = nn.ModuleList()\n",
        "        for i in range(depth):\n",
        "            self.down_path.append(\n",
        "                ConvBlock(prev_channels, first_channels * 2**i, 3,\n",
        "                          padding=padding, batch_norm=batch_norm,\n",
        "                          activation=activation))\n",
        "            prev_channels = first_channels * 2**i\n",
        "\n",
        "        self.bottleneck_path = nn.ModuleList()\n",
        "        for i in range(bottleneck_depth):\n",
        "            bneck_in = prev_channels if i == 0 else prev_channels * 2\n",
        "            self.bottleneck_path.append(\n",
        "                conv(bneck_in, prev_channels * 2, 3,\n",
        "                     dilation=2**i, padding=2**i, activation=activation))\n",
        "\n",
        "        prev_channels *= 2\n",
        "\n",
        "        self.up_path = nn.ModuleList()\n",
        "        for i in reversed(range(depth)):\n",
        "            self.up_path.append(\n",
        "                UpBlockWithSkip(prev_channels, first_channels * 2**i, 3,\n",
        "                                up_mode=up_mode, padding=padding,\n",
        "                                batch_norm=batch_norm,\n",
        "                                activation=activation))\n",
        "            prev_channels = first_channels * 2**i\n",
        "\n",
        "        self.last = nn.Conv2d(prev_channels, classes, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        bridges = []\n",
        "        for i, down in enumerate(self.down_path):\n",
        "            x = down(x)\n",
        "            bridges.append(x)\n",
        "            x = F.avg_pool2d(x, 2)\n",
        "\n",
        "        dilated_layers = []\n",
        "        for i, bneck in enumerate(self.bottleneck_path):\n",
        "            if self.bottleneck_type == 'cascade':\n",
        "                x = bneck(x)\n",
        "                dilated_layers.append(x.unsqueeze(-1))\n",
        "            elif self.bottleneck_type == 'parallel':\n",
        "                dilated_layers.append(bneck(x.unsqueeze(-1)))\n",
        "        x = torch.cat(dilated_layers, dim=-1)\n",
        "        x = torch.sum(x, dim=-1)\n",
        "\n",
        "        for i, up in enumerate(self.up_path):\n",
        "            x = up(x, bridges[-i-1])\n",
        "\n",
        "        return self.last(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hxZ-bpNo4mLM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "55c6de78-f24f-4c94-8f83-01b4cb846568"
      },
      "source": [
        "# net = UNet(in_channels=3, out_channels=4, num_hidden_features=[64, 128, 256], \n",
        "#            num_dilated_convs=2, n_resblocks=2, \n",
        "#            dropout_min=0., dropout_max=0.2)\n",
        "\n",
        "net = DilatedUNet(in_channels=3, classes=4, depth=5)\n",
        "\n",
        "print(net)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DilatedUNet(\n",
            "  (down_path): ModuleList(\n",
            "    (0): ConvBlock(\n",
            "      (block): Sequential(\n",
            "        (0): ConvActivation(\n",
            "          (conv): Conv2d(3, 44, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (activation): ReLU(inplace=True)\n",
            "        )\n",
            "        (1): ConvActivation(\n",
            "          (conv): Conv2d(44, 44, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (activation): ReLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (1): ConvBlock(\n",
            "      (block): Sequential(\n",
            "        (0): ConvActivation(\n",
            "          (conv): Conv2d(44, 88, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (activation): ReLU(inplace=True)\n",
            "        )\n",
            "        (1): ConvActivation(\n",
            "          (conv): Conv2d(88, 88, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (activation): ReLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (2): ConvBlock(\n",
            "      (block): Sequential(\n",
            "        (0): ConvActivation(\n",
            "          (conv): Conv2d(88, 176, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (activation): ReLU(inplace=True)\n",
            "        )\n",
            "        (1): ConvActivation(\n",
            "          (conv): Conv2d(176, 176, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (activation): ReLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (3): ConvBlock(\n",
            "      (block): Sequential(\n",
            "        (0): ConvActivation(\n",
            "          (conv): Conv2d(176, 352, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (activation): ReLU(inplace=True)\n",
            "        )\n",
            "        (1): ConvActivation(\n",
            "          (conv): Conv2d(352, 352, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (activation): ReLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (4): ConvBlock(\n",
            "      (block): Sequential(\n",
            "        (0): ConvActivation(\n",
            "          (conv): Conv2d(352, 704, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (activation): ReLU(inplace=True)\n",
            "        )\n",
            "        (1): ConvActivation(\n",
            "          (conv): Conv2d(704, 704, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (activation): ReLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (bottleneck_path): ModuleList(\n",
            "    (0): ConvActivation(\n",
            "      (conv): Conv2d(704, 1408, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (activation): ReLU(inplace=True)\n",
            "    )\n",
            "    (1): ConvActivation(\n",
            "      (conv): Conv2d(1408, 1408, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
            "      (activation): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): ConvActivation(\n",
            "      (conv): Conv2d(1408, 1408, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4))\n",
            "      (activation): ReLU(inplace=True)\n",
            "    )\n",
            "    (3): ConvActivation(\n",
            "      (conv): Conv2d(1408, 1408, kernel_size=(3, 3), stride=(1, 1), padding=(8, 8), dilation=(8, 8))\n",
            "      (activation): ReLU(inplace=True)\n",
            "    )\n",
            "    (4): ConvActivation(\n",
            "      (conv): Conv2d(1408, 1408, kernel_size=(3, 3), stride=(1, 1), padding=(16, 16), dilation=(16, 16))\n",
            "      (activation): ReLU(inplace=True)\n",
            "    )\n",
            "    (5): ConvActivation(\n",
            "      (conv): Conv2d(1408, 1408, kernel_size=(3, 3), stride=(1, 1), padding=(32, 32), dilation=(32, 32))\n",
            "      (activation): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (up_path): ModuleList(\n",
            "    (0): UpBlockWithSkip(\n",
            "      (up): ConvTranspose2d(1408, 704, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "      (conv_block): ConvBlock(\n",
            "        (block): Sequential(\n",
            "          (0): ConvActivation(\n",
            "            (conv): Conv2d(1408, 704, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            (activation): ReLU(inplace=True)\n",
            "          )\n",
            "          (1): ConvActivation(\n",
            "            (conv): Conv2d(704, 704, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            (activation): ReLU(inplace=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (1): UpBlockWithSkip(\n",
            "      (up): ConvTranspose2d(704, 352, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "      (conv_block): ConvBlock(\n",
            "        (block): Sequential(\n",
            "          (0): ConvActivation(\n",
            "            (conv): Conv2d(704, 352, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            (activation): ReLU(inplace=True)\n",
            "          )\n",
            "          (1): ConvActivation(\n",
            "            (conv): Conv2d(352, 352, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            (activation): ReLU(inplace=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (2): UpBlockWithSkip(\n",
            "      (up): ConvTranspose2d(352, 176, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "      (conv_block): ConvBlock(\n",
            "        (block): Sequential(\n",
            "          (0): ConvActivation(\n",
            "            (conv): Conv2d(352, 176, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            (activation): ReLU(inplace=True)\n",
            "          )\n",
            "          (1): ConvActivation(\n",
            "            (conv): Conv2d(176, 176, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            (activation): ReLU(inplace=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (3): UpBlockWithSkip(\n",
            "      (up): ConvTranspose2d(176, 88, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "      (conv_block): ConvBlock(\n",
            "        (block): Sequential(\n",
            "          (0): ConvActivation(\n",
            "            (conv): Conv2d(176, 88, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            (activation): ReLU(inplace=True)\n",
            "          )\n",
            "          (1): ConvActivation(\n",
            "            (conv): Conv2d(88, 88, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            (activation): ReLU(inplace=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (4): UpBlockWithSkip(\n",
            "      (up): ConvTranspose2d(88, 44, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "      (conv_block): ConvBlock(\n",
            "        (block): Sequential(\n",
            "          (0): ConvActivation(\n",
            "            (conv): Conv2d(88, 44, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            (activation): ReLU(inplace=True)\n",
            "          )\n",
            "          (1): ConvActivation(\n",
            "            (conv): Conv2d(44, 44, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            (activation): ReLU(inplace=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (last): Conv2d(44, 4, kernel_size=(1, 1), stride=(1, 1))\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uWbxhIkrmSl7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "bf2fc0e1-aebe-45c7-b656-6238396ad7a0"
      },
      "source": [
        "input = torch.randn(16, 3, 320, 320)\n",
        "output = net(input)\n",
        "print(output)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[[[ 0.0226,  0.0278,  0.0194,  ...,  0.0214,  0.0171,  0.0257],\n",
            "          [ 0.0236,  0.0196,  0.0312,  ...,  0.0274,  0.0282,  0.0258],\n",
            "          [ 0.0210,  0.0256,  0.0272,  ...,  0.0295,  0.0239,  0.0250],\n",
            "          ...,\n",
            "          [ 0.0208,  0.0270,  0.0110,  ...,  0.0273,  0.0222,  0.0279],\n",
            "          [ 0.0267,  0.0278,  0.0314,  ...,  0.0371,  0.0219,  0.0300],\n",
            "          [ 0.0270,  0.0299,  0.0247,  ...,  0.0242,  0.0230,  0.0287]],\n",
            "\n",
            "         [[-0.1230, -0.1218, -0.1299,  ..., -0.1290, -0.1358, -0.1313],\n",
            "          [-0.1323, -0.1300, -0.1306,  ..., -0.1283, -0.1337, -0.1271],\n",
            "          [-0.1315, -0.1158, -0.1212,  ..., -0.1350, -0.1235, -0.1312],\n",
            "          ...,\n",
            "          [-0.1283, -0.1232, -0.1355,  ..., -0.1260, -0.1171, -0.1308],\n",
            "          [-0.1209, -0.1230, -0.1258,  ..., -0.1160, -0.1266, -0.1274],\n",
            "          [-0.1280, -0.1287, -0.1275,  ..., -0.1268, -0.1234, -0.1243]],\n",
            "\n",
            "         [[ 0.0389,  0.0436,  0.0301,  ...,  0.0441,  0.0437,  0.0436],\n",
            "          [ 0.0440,  0.0477,  0.0461,  ...,  0.0453,  0.0492,  0.0440],\n",
            "          [ 0.0409,  0.0506,  0.0440,  ...,  0.0450,  0.0439,  0.0446],\n",
            "          ...,\n",
            "          [ 0.0454,  0.0469,  0.0448,  ...,  0.0530,  0.0367,  0.0424],\n",
            "          [ 0.0479,  0.0508,  0.0515,  ...,  0.0417,  0.0426,  0.0532],\n",
            "          [ 0.0474,  0.0554,  0.0539,  ...,  0.0517,  0.0535,  0.0452]],\n",
            "\n",
            "         [[ 0.0300,  0.0281,  0.0314,  ...,  0.0301,  0.0348,  0.0335],\n",
            "          [ 0.0380,  0.0375,  0.0416,  ...,  0.0312,  0.0397,  0.0331],\n",
            "          [ 0.0390,  0.0410,  0.0320,  ...,  0.0460,  0.0385,  0.0300],\n",
            "          ...,\n",
            "          [ 0.0437,  0.0367,  0.0364,  ...,  0.0313,  0.0385,  0.0359],\n",
            "          [ 0.0472,  0.0341,  0.0309,  ...,  0.0376,  0.0313,  0.0352],\n",
            "          [ 0.0413,  0.0434,  0.0425,  ...,  0.0410,  0.0402,  0.0323]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0177,  0.0225,  0.0257,  ...,  0.0221,  0.0214,  0.0242],\n",
            "          [ 0.0289,  0.0263,  0.0212,  ...,  0.0173,  0.0204,  0.0198],\n",
            "          [ 0.0244,  0.0298,  0.0205,  ...,  0.0274,  0.0256,  0.0175],\n",
            "          ...,\n",
            "          [ 0.0327,  0.0209,  0.0274,  ...,  0.0162,  0.0180,  0.0316],\n",
            "          [ 0.0205,  0.0273,  0.0239,  ...,  0.0182,  0.0270,  0.0290],\n",
            "          [ 0.0302,  0.0340,  0.0227,  ...,  0.0222,  0.0223,  0.0284]],\n",
            "\n",
            "         [[-0.1281, -0.1281, -0.1245,  ..., -0.1269, -0.1347, -0.1288],\n",
            "          [-0.1232, -0.1252, -0.1364,  ..., -0.1227, -0.1247, -0.1379],\n",
            "          [-0.1215, -0.1243, -0.1293,  ..., -0.1218, -0.1158, -0.1324],\n",
            "          ...,\n",
            "          [-0.1219, -0.1221, -0.1094,  ..., -0.1255, -0.1221, -0.1276],\n",
            "          [-0.1301, -0.1304, -0.1201,  ..., -0.1293, -0.1330, -0.1234],\n",
            "          [-0.1266, -0.1210, -0.1296,  ..., -0.1311, -0.1275, -0.1239]],\n",
            "\n",
            "         [[ 0.0354,  0.0435,  0.0441,  ...,  0.0389,  0.0403,  0.0430],\n",
            "          [ 0.0514,  0.0455,  0.0482,  ...,  0.0371,  0.0412,  0.0485],\n",
            "          [ 0.0471,  0.0445,  0.0415,  ...,  0.0426,  0.0455,  0.0476],\n",
            "          ...,\n",
            "          [ 0.0500,  0.0541,  0.0539,  ...,  0.0410,  0.0501,  0.0415],\n",
            "          [ 0.0439,  0.0547,  0.0626,  ...,  0.0422,  0.0453,  0.0382],\n",
            "          [ 0.0512,  0.0553,  0.0520,  ...,  0.0553,  0.0549,  0.0445]],\n",
            "\n",
            "         [[ 0.0300,  0.0318,  0.0288,  ...,  0.0288,  0.0291,  0.0305],\n",
            "          [ 0.0366,  0.0394,  0.0341,  ...,  0.0302,  0.0315,  0.0276],\n",
            "          [ 0.0411,  0.0431,  0.0388,  ...,  0.0387,  0.0448,  0.0336],\n",
            "          ...,\n",
            "          [ 0.0492,  0.0409,  0.0331,  ...,  0.0397,  0.0357,  0.0305],\n",
            "          [ 0.0411,  0.0402,  0.0317,  ...,  0.0356,  0.0384,  0.0265],\n",
            "          [ 0.0407,  0.0446,  0.0339,  ...,  0.0371,  0.0380,  0.0290]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0218,  0.0181,  0.0198,  ...,  0.0162,  0.0175,  0.0227],\n",
            "          [ 0.0230,  0.0285,  0.0192,  ...,  0.0114,  0.0233,  0.0295],\n",
            "          [ 0.0232,  0.0232,  0.0129,  ...,  0.0278,  0.0252,  0.0255],\n",
            "          ...,\n",
            "          [ 0.0199,  0.0157,  0.0309,  ...,  0.0325,  0.0213,  0.0275],\n",
            "          [ 0.0256,  0.0190,  0.0224,  ...,  0.0180,  0.0277,  0.0302],\n",
            "          [ 0.0273,  0.0236,  0.0230,  ...,  0.0251,  0.0254,  0.0245]],\n",
            "\n",
            "         [[-0.1264, -0.1301, -0.1328,  ..., -0.1298, -0.1339, -0.1335],\n",
            "          [-0.1217, -0.1234, -0.1264,  ..., -0.1306, -0.1304, -0.1343],\n",
            "          [-0.1237, -0.1287, -0.1388,  ..., -0.1206, -0.1239, -0.1353],\n",
            "          ...,\n",
            "          [-0.1228, -0.1237, -0.1391,  ..., -0.1239, -0.1277, -0.1261],\n",
            "          [-0.1298, -0.1398, -0.1237,  ..., -0.1229, -0.1242, -0.1321],\n",
            "          [-0.1272, -0.1307, -0.1288,  ..., -0.1325, -0.1205, -0.1329]],\n",
            "\n",
            "         [[ 0.0386,  0.0428,  0.0446,  ...,  0.0465,  0.0406,  0.0483],\n",
            "          [ 0.0411,  0.0377,  0.0462,  ...,  0.0367,  0.0534,  0.0557],\n",
            "          [ 0.0489,  0.0411,  0.0470,  ...,  0.0579,  0.0411,  0.0467],\n",
            "          ...,\n",
            "          [ 0.0481,  0.0592,  0.0314,  ...,  0.0361,  0.0388,  0.0478],\n",
            "          [ 0.0479,  0.0401,  0.0436,  ...,  0.0559,  0.0523,  0.0443],\n",
            "          [ 0.0512,  0.0550,  0.0575,  ...,  0.0509,  0.0512,  0.0437]],\n",
            "\n",
            "         [[ 0.0272,  0.0318,  0.0326,  ...,  0.0240,  0.0339,  0.0305],\n",
            "          [ 0.0371,  0.0429,  0.0356,  ...,  0.0295,  0.0397,  0.0351],\n",
            "          [ 0.0327,  0.0413,  0.0335,  ...,  0.0361,  0.0326,  0.0444],\n",
            "          ...,\n",
            "          [ 0.0324,  0.0263,  0.0417,  ...,  0.0375,  0.0383,  0.0332],\n",
            "          [ 0.0496,  0.0492,  0.0427,  ...,  0.0303,  0.0389,  0.0348],\n",
            "          [ 0.0415,  0.0463,  0.0325,  ...,  0.0428,  0.0348,  0.0348]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 0.0226,  0.0270,  0.0212,  ...,  0.0253,  0.0273,  0.0192],\n",
            "          [ 0.0264,  0.0219,  0.0244,  ...,  0.0201,  0.0192,  0.0303],\n",
            "          [ 0.0226,  0.0185,  0.0141,  ...,  0.0381,  0.0285,  0.0247],\n",
            "          ...,\n",
            "          [ 0.0228,  0.0287,  0.0180,  ...,  0.0258,  0.0148,  0.0270],\n",
            "          [ 0.0246,  0.0190,  0.0183,  ...,  0.0299,  0.0223,  0.0273],\n",
            "          [ 0.0367,  0.0283,  0.0183,  ...,  0.0276,  0.0269,  0.0233]],\n",
            "\n",
            "         [[-0.1243, -0.1287, -0.1318,  ..., -0.1255, -0.1305, -0.1304],\n",
            "          [-0.1187, -0.1297, -0.1285,  ..., -0.1225, -0.1319, -0.1231],\n",
            "          [-0.1273, -0.1332, -0.1248,  ..., -0.1229, -0.1272, -0.1258],\n",
            "          ...,\n",
            "          [-0.1253, -0.1211, -0.1375,  ..., -0.1296, -0.1391, -0.1294],\n",
            "          [-0.1304, -0.1340, -0.1213,  ..., -0.1126, -0.1338, -0.1296],\n",
            "          [-0.1191, -0.1290, -0.1237,  ..., -0.1228, -0.1288, -0.1299]],\n",
            "\n",
            "         [[ 0.0437,  0.0414,  0.0455,  ...,  0.0375,  0.0391,  0.0423],\n",
            "          [ 0.0496,  0.0504,  0.0493,  ...,  0.0405,  0.0418,  0.0447],\n",
            "          [ 0.0468,  0.0552,  0.0391,  ...,  0.0397,  0.0407,  0.0430],\n",
            "          ...,\n",
            "          [ 0.0471,  0.0437,  0.0454,  ...,  0.0433,  0.0366,  0.0420],\n",
            "          [ 0.0466,  0.0536,  0.0592,  ...,  0.0506,  0.0519,  0.0532],\n",
            "          [ 0.0534,  0.0529,  0.0547,  ...,  0.0452,  0.0525,  0.0510]],\n",
            "\n",
            "         [[ 0.0333,  0.0359,  0.0274,  ...,  0.0259,  0.0257,  0.0302],\n",
            "          [ 0.0459,  0.0374,  0.0350,  ...,  0.0305,  0.0408,  0.0333],\n",
            "          [ 0.0471,  0.0345,  0.0325,  ...,  0.0441,  0.0322,  0.0317],\n",
            "          ...,\n",
            "          [ 0.0511,  0.0505,  0.0411,  ...,  0.0494,  0.0485,  0.0337],\n",
            "          [ 0.0411,  0.0424,  0.0476,  ...,  0.0403,  0.0331,  0.0336],\n",
            "          [ 0.0468,  0.0398,  0.0405,  ...,  0.0319,  0.0390,  0.0333]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0254,  0.0282,  0.0183,  ...,  0.0241,  0.0197,  0.0238],\n",
            "          [ 0.0237,  0.0200,  0.0325,  ...,  0.0223,  0.0294,  0.0242],\n",
            "          [ 0.0299,  0.0270,  0.0273,  ...,  0.0210,  0.0222,  0.0212],\n",
            "          ...,\n",
            "          [ 0.0282,  0.0320,  0.0284,  ...,  0.0231,  0.0249,  0.0196],\n",
            "          [ 0.0233,  0.0259,  0.0252,  ...,  0.0177,  0.0292,  0.0291],\n",
            "          [ 0.0278,  0.0205,  0.0209,  ...,  0.0247,  0.0219,  0.0245]],\n",
            "\n",
            "         [[-0.1246, -0.1272, -0.1279,  ..., -0.1259, -0.1320, -0.1380],\n",
            "          [-0.1240, -0.1225, -0.1232,  ..., -0.1273, -0.1336, -0.1237],\n",
            "          [-0.1265, -0.1235, -0.1358,  ..., -0.1225, -0.1277, -0.1291],\n",
            "          ...,\n",
            "          [-0.1220, -0.1264, -0.1349,  ..., -0.1245, -0.1238, -0.1343],\n",
            "          [-0.1261, -0.1245, -0.1294,  ..., -0.1303, -0.1281, -0.1281],\n",
            "          [-0.1261, -0.1234, -0.1307,  ..., -0.1215, -0.1257, -0.1278]],\n",
            "\n",
            "         [[ 0.0431,  0.0397,  0.0349,  ...,  0.0361,  0.0450,  0.0449],\n",
            "          [ 0.0410,  0.0406,  0.0480,  ...,  0.0437,  0.0455,  0.0438],\n",
            "          [ 0.0472,  0.0469,  0.0451,  ...,  0.0526,  0.0484,  0.0431],\n",
            "          ...,\n",
            "          [ 0.0572,  0.0396,  0.0397,  ...,  0.0497,  0.0486,  0.0451],\n",
            "          [ 0.0432,  0.0489,  0.0530,  ...,  0.0468,  0.0517,  0.0507],\n",
            "          [ 0.0534,  0.0516,  0.0548,  ...,  0.0569,  0.0526,  0.0517]],\n",
            "\n",
            "         [[ 0.0301,  0.0311,  0.0260,  ...,  0.0368,  0.0284,  0.0324],\n",
            "          [ 0.0407,  0.0320,  0.0384,  ...,  0.0319,  0.0367,  0.0386],\n",
            "          [ 0.0463,  0.0437,  0.0441,  ...,  0.0311,  0.0335,  0.0289],\n",
            "          ...,\n",
            "          [ 0.0419,  0.0472,  0.0390,  ...,  0.0302,  0.0403,  0.0326],\n",
            "          [ 0.0440,  0.0410,  0.0372,  ...,  0.0419,  0.0371,  0.0361],\n",
            "          [ 0.0437,  0.0407,  0.0412,  ...,  0.0412,  0.0391,  0.0324]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0237,  0.0178,  0.0215,  ...,  0.0183,  0.0171,  0.0267],\n",
            "          [ 0.0288,  0.0239,  0.0251,  ...,  0.0314,  0.0246,  0.0223],\n",
            "          [ 0.0321,  0.0240,  0.0240,  ...,  0.0315,  0.0235,  0.0247],\n",
            "          ...,\n",
            "          [ 0.0246,  0.0228,  0.0196,  ...,  0.0251,  0.0171,  0.0225],\n",
            "          [ 0.0246,  0.0298,  0.0286,  ...,  0.0194,  0.0228,  0.0227],\n",
            "          [ 0.0261,  0.0249,  0.0226,  ...,  0.0282,  0.0235,  0.0278]],\n",
            "\n",
            "         [[-0.1282, -0.1266, -0.1364,  ..., -0.1337, -0.1340, -0.1277],\n",
            "          [-0.1249, -0.1273, -0.1179,  ..., -0.1311, -0.1260, -0.1308],\n",
            "          [-0.1203, -0.1345, -0.1272,  ..., -0.1202, -0.1273, -0.1276],\n",
            "          ...,\n",
            "          [-0.1272, -0.1272, -0.1277,  ..., -0.1324, -0.1277, -0.1286],\n",
            "          [-0.1330, -0.1303, -0.1214,  ..., -0.1301, -0.1160, -0.1298],\n",
            "          [-0.1234, -0.1275, -0.1280,  ..., -0.1251, -0.1286, -0.1232]],\n",
            "\n",
            "         [[ 0.0454,  0.0405,  0.0482,  ...,  0.0384,  0.0468,  0.0480],\n",
            "          [ 0.0443,  0.0602,  0.0447,  ...,  0.0496,  0.0454,  0.0488],\n",
            "          [ 0.0415,  0.0540,  0.0462,  ...,  0.0517,  0.0497,  0.0457],\n",
            "          ...,\n",
            "          [ 0.0383,  0.0546,  0.0541,  ...,  0.0474,  0.0488,  0.0542],\n",
            "          [ 0.0435,  0.0551,  0.0415,  ...,  0.0519,  0.0491,  0.0470],\n",
            "          [ 0.0485,  0.0491,  0.0539,  ...,  0.0491,  0.0555,  0.0458]],\n",
            "\n",
            "         [[ 0.0353,  0.0275,  0.0245,  ...,  0.0266,  0.0262,  0.0318],\n",
            "          [ 0.0486,  0.0359,  0.0444,  ...,  0.0367,  0.0420,  0.0327],\n",
            "          [ 0.0453,  0.0326,  0.0288,  ...,  0.0305,  0.0320,  0.0346],\n",
            "          ...,\n",
            "          [ 0.0450,  0.0425,  0.0364,  ...,  0.0364,  0.0437,  0.0395],\n",
            "          [ 0.0425,  0.0416,  0.0389,  ...,  0.0378,  0.0409,  0.0351],\n",
            "          [ 0.0399,  0.0335,  0.0414,  ...,  0.0434,  0.0332,  0.0352]]]],\n",
            "       grad_fn=<MkldnnConvolutionBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fpgj2fVnm_aG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "11b48e37-7f05-4cc9-dd78-a568b7fd8734"
      },
      "source": [
        "output.min()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(-0.1624, grad_fn=<MinBackward1>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VSO71epW2-4_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9324cc4a-7360-4876-8555-834b1fdd0802"
      },
      "source": [
        "output.max()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.0825, grad_fn=<MaxBackward1>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_vZ2bKLjJASr",
        "colab_type": "text"
      },
      "source": [
        "# Load Data\n",
        "In smp, the involved preprocessings include: normalization and resizing. We can simply normalize the data by dividing them by 255. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3pb_Ej5iUipH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load data\n",
        "\n",
        "# Preprocess\n",
        "\n",
        "# Convert into pytorch format \"DataLoader\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQpDa01dVlJc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path = '/content/gdrive/My Drive/kaggle_cloud/data'\n",
        "\n",
        "def get_data(path, n_samples=None):\n",
        "  \"\"\"\n",
        "  Read the taining data information, including image id and labels. \n",
        "  \"\"\"\n",
        "  train = pd.read_csv(f'{path}/train.csv')\n",
        "  sub = pd.read_csv(f'{path}/sample_submission.csv')\n",
        "  print(\"Reading the training csv...\")\n",
        "  print(train.columns)\n",
        "  print(train.shape)\n",
        "\n",
        "  n_train = len(os.listdir(f'{path}/train_images'))\n",
        "  print(\"Reading the training images...\")\n",
        "  print(f'There are {n_train} images in the original train dataset')\n",
        "\n",
        "  if n_samples: \n",
        "    train = train.iloc[:n_samples, :]\n",
        "    print(f'Use {n_samples} images within the training dataset.')\n",
        "\n",
        "\n",
        "  train['label'] = train['Image_Label'].apply(lambda x: x.split('_')[1])\n",
        "  train['im_id'] = train['Image_Label'].apply(lambda x: x.split('_')[0])\n",
        "\n",
        "  sub['label'] = sub['Image_Label'].apply(lambda x: x.split('_')[1])\n",
        "  sub['im_id'] = sub['Image_Label'].apply(lambda x: x.split('_')[0])\n",
        "\n",
        "  return train, sub\n",
        "\n",
        "\n",
        "def make_mask(df: pd.DataFrame, image_name: str='img.jpg', shape: tuple = (1400, 2100)):\n",
        "    \"\"\"\n",
        "    Create mask based on df, image name and shape.\n",
        "\n",
        "    [OUTPUTS]:\n",
        "    masks: an array with shape (shape[0], shape[1], 4).\n",
        "      Mask for each class labels.\n",
        "    \"\"\"\n",
        "    encoded_masks = df.loc[df['im_id'] == image_name, 'EncodedPixels']\n",
        "    masks = np.zeros((shape[0], shape[1], 4), dtype=np.float32)\n",
        "\n",
        "    for idx, label in enumerate(encoded_masks.values):\n",
        "        if label is not np.nan:\n",
        "            mask = rle_decode(label)\n",
        "            masks[:, :, idx] = mask\n",
        "            \n",
        "    return masks\n",
        "\n",
        "def get_img(x, folder: str='train_images'):\n",
        "    \"\"\"\n",
        "    Return image based on image name and folder.\n",
        "    \"\"\"\n",
        "    data_folder = f\"{path}/{folder}\"\n",
        "    image_path = os.path.join(data_folder, x)\n",
        "    img = cv2.imread(image_path)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    return img\n",
        "\n",
        "\n",
        "def rle_decode(mask_rle: str = '', shape: tuple = (1400, 2100)):\n",
        "    '''\n",
        "    Decode rle encoded mask.\n",
        "    \n",
        "    :param mask_rle: run-length as string formatted (start length)\n",
        "    :param shape: (height, width) of array to return \n",
        "    Returns numpy array, 1 - mask, 0 - background\n",
        "    '''\n",
        "    s = mask_rle.split()\n",
        "    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n",
        "    starts -= 1\n",
        "    ends = starts + lengths\n",
        "    img = np.zeros(shape[0] * shape[1], dtype=np.uint8)\n",
        "    for lo, hi in zip(starts, ends):\n",
        "        img[lo:hi] = 1\n",
        "    return img.reshape(shape, order='F')\n",
        "\n",
        "def mask2rle(img):\n",
        "    '''\n",
        "    Convert mask to rle.\n",
        "    img: numpy array, 1 - mask, 0 - background\n",
        "    Returns run length as string formated\n",
        "    '''\n",
        "    pixels= img.T.flatten()\n",
        "    pixels = np.concatenate([[0], pixels, [0]])\n",
        "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
        "    runs[1::2] -= runs[::2]\n",
        "    return ' '.join(str(x) for x in runs)\n",
        "\n",
        "\n",
        "def get_training_augmentation():\n",
        "    \"\"\"\n",
        "    Define the preprocessing for the training data. \n",
        "    \"\"\"\n",
        "    train_transform = [\n",
        "        albu.HorizontalFlip(p=0.5),\n",
        "        albu.ShiftScaleRotate(scale_limit=0.5, rotate_limit=0, shift_limit=0.1, p=0.5, border_mode=0),\n",
        "        albu.GridDistortion(p=0.5),\n",
        "        albu.OpticalDistortion(p=0.5, distort_limit=2, shift_limit=0.5),\n",
        "        # albu.Resize(320, 640)\n",
        "        albu.Resize(160, 320)\n",
        "    ]\n",
        "    return albu.Compose(train_transform)\n",
        "\n",
        "def get_validation_augmentation():\n",
        "    \"\"\"Add paddings to make image shape divisible by 32\"\"\"\n",
        "    test_transform = [\n",
        "        # albu.Resize(320, 640)\n",
        "        albu.Resize(160, 320)\n",
        "    ]\n",
        "    return albu.Compose(test_transform)\n",
        "\n",
        "def split_data(train, sub):\n",
        "  \"\"\"\n",
        "  Split the training dataset into train/valid datasets, and use all the data in \n",
        "  the submission dataset as test data. \n",
        "\n",
        "  [OUTPUTS]:\n",
        "  train_ids/valid_ids/test_ids: array of image ids(str). \n",
        "  \"\"\"\n",
        "  train_labels = train.loc[train['EncodedPixels'].isnull() == False, 'Image_Label']\n",
        "  id_mask_count = train_labels.apply(lambda x: x.split('_')[0]).value_counts()\n",
        "  id_mask_count = id_mask_count.reset_index().rename(columns={'index': 'img_id', 'Image_Label': 'count'})\n",
        "  train_ids, valid_ids = train_test_split(id_mask_count['img_id'].values,\n",
        "                                          random_state=42,\n",
        "                                          stratify=id_mask_count['count'],\n",
        "                                          test_size=0.1)\n",
        " \n",
        "  # Alternatively, we can use sub['im_id'] directly. \n",
        "  test_ids = sub['Image_Label'].apply(lambda x: x.split('_')[0]).drop_duplicates().values\n",
        "  \n",
        "  return train_ids, valid_ids, test_ids\n",
        "\n",
        "\n",
        "# Convert the augmenttation into standdard transform\n",
        "# Add others transforms: toTensor (the range of value has been converted to [0, 1] in \n",
        "# toTensor)\n",
        "\n",
        "class ToTensor(object):\n",
        "    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n",
        "\n",
        "    def __call__(self, sample):\n",
        "        image, mask = sample['image'], sample['mask']\n",
        "\n",
        "        # swap color axis because\n",
        "        # numpy image: H x W x C\n",
        "        # torch image: C X H X W\n",
        "        image = image.transpose((2, 0, 1))\n",
        "        return {'image': torch.from_numpy(image),\n",
        "                'landmarks': torch.from_numpy(mask)}\n",
        "\n",
        "\n",
        "class CloudDataset(Dataset):\n",
        "    def __init__(self, df: pd.DataFrame = None, datatype: str = 'train', img_ids: np.array = None,\n",
        "                 transforms = albu.Compose([albu.HorizontalFlip(),AT.ToTensor()]),\n",
        "                 preprocessing=None):\n",
        "        \"\"\"\n",
        "        [INPUTS]:\n",
        "        df: a pandas dataframe. \n",
        "          The image information dataframe, obtained from function \"get_data()\".\n",
        "        datatype: string. \n",
        "          Whether it is 'train' or 'test'. \n",
        "        \n",
        "        \"\"\"\n",
        "        self.df = df\n",
        "        if datatype != 'test':\n",
        "            self.data_folder = f\"{path}/train_images\"\n",
        "        else:\n",
        "            self.data_folder = f\"{path}/test_images\"\n",
        "        self.img_ids = img_ids\n",
        "        self.transforms = transforms\n",
        "        self.preprocessing = preprocessing\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_name = self.img_ids[idx]\n",
        "        mask = make_mask(self.df, image_name)\n",
        "        image_path = os.path.join(self.data_folder, image_name)\n",
        "        img = cv2.imread(image_path)\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        augmented = self.transforms(image=img, mask=mask)\n",
        "        img = augmented['image']\n",
        "        mask = augmented['mask']\n",
        "\n",
        "        # if self.preprocessing:\n",
        "        #     preprocessed = self.preprocessing(image=img, mask=mask)\n",
        "        #     img = preprocessed['image']\n",
        "        #     mask = preprocessed['mask']\n",
        "        if self.preprocessing:\n",
        "            img = self.preprocessing(img)\n",
        "            mask = self.preprocessing(mask)\n",
        "\n",
        "        return img, mask\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_ids)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wvLjfYAjWDff",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "dd95dfe8-ebf2-416f-f439-70c5b7342c45"
      },
      "source": [
        "train, sub = get_data(path)\n",
        "train_ids, valid_ids, test_ids = split_data(train, sub)\n",
        "\n",
        "num_workers = 0\n",
        "bs = 16\n",
        "train_dataset = CloudDataset(df=train, datatype='train', img_ids=train_ids, \n",
        "                             transforms = get_training_augmentation(), \n",
        "                             preprocessing=transforms.ToTensor())\n",
        "\n",
        "valid_dataset = CloudDataset(df=train, datatype='valid', img_ids=valid_ids, \n",
        "                             transforms = get_validation_augmentation(), \n",
        "                             preprocessing=transforms.ToTensor())\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=bs, shuffle=True, \n",
        "                          num_workers=num_workers)\n",
        "valid_loader = DataLoader(valid_dataset, batch_size=bs, shuffle=False, \n",
        "                          num_workers=num_workers)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading the training csv...\n",
            "Index(['Image_Label', 'EncodedPixels'], dtype='object')\n",
            "(22184, 2)\n",
            "Reading the training images...\n",
            "There are 5546 images in the original train dataset\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K7aW6fFkhHZU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "5f2416dd-6554-44ac-fe39-3a72d0f71426"
      },
      "source": [
        "for i in range(len(train_dataset)):\n",
        "    img, mask = train_dataset[i]\n",
        "\n",
        "    print(i, img.size(), mask.size())\n",
        "\n",
        "    if i == 3:\n",
        "        break"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 torch.Size([3, 160, 320]) torch.Size([4, 160, 320])\n",
            "1 torch.Size([3, 160, 320]) torch.Size([4, 160, 320])\n",
            "2 torch.Size([3, 160, 320]) torch.Size([4, 160, 320])\n",
            "3 torch.Size([3, 160, 320]) torch.Size([4, 160, 320])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WxosKwgsEyMv",
        "colab_type": "text"
      },
      "source": [
        "# Model Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zlENblcH3qNR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u1hA_Zm-E4JI",
        "colab_type": "text"
      },
      "source": [
        "# Model Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4VMYLzYeE514",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}