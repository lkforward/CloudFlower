{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "run_cloud_model.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "76uu3wAFBCpw",
        "jk4m76X-s8Ga"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lkforward/flower/blob/master/run_cloud_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nIqiGJi69ZBy",
        "colab_type": "code",
        "outputId": "9b228305-fd36-4dc8-d1d9-ed9cfd4b70cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 79
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.test.gpu_device_name()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/device:GPU:0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ECF3WDad4p8d",
        "colab_type": "code",
        "outputId": "fdf6f3b8-62b6-4be6-d0e8-0bc8e86ddf40",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive', force_remount=True)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y-p1qwRY34Gc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b6b3e45d-abc6-44bb-8845-4a8e3ece1087"
      },
      "source": [
        "!pip install catalyst\n",
        "!pip install pretrainedmodels\n",
        "!pip install git+https://github.com/qubvel/segmentation_models.pytorch\n",
        "!pip install pytorch_toolbelt\n",
        "!pip install torchvision==0.4\n",
        "!pip install albumentations==0.3.2"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting catalyst\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/34/c2/1bba0179006810210b256e2201e002507e36eae121c171ea31533a87a5d3/catalyst-19.11.2-py2.py3-none-any.whl (290kB)\n",
            "\u001b[K     |████████████████████████████████| 296kB 3.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn>=0.20 in /usr/local/lib/python3.6/dist-packages (from catalyst) (0.21.3)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.6/dist-packages (from catalyst) (1.15.0)\n",
            "Collecting tqdm>=4.33.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b9/08/8505f192efc72bfafec79655e1d8351d219e2b80b0dec4ae71f50934c17a/tqdm-4.38.0-py2.py3-none-any.whl (53kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 6.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from catalyst) (1.3.1+cu100)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.6/dist-packages (from catalyst) (3.4.7.28)\n",
            "Requirement already satisfied: torchvision>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from catalyst) (0.4.2+cu100)\n",
            "Requirement already satisfied: scikit-image>=0.14.2 in /usr/local/lib/python3.6/dist-packages (from catalyst) (0.15.0)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.6/dist-packages (from catalyst) (2.4.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.6/dist-packages (from catalyst) (3.13)\n",
            "Requirement already satisfied: plotly>=4.1.0 in /usr/local/lib/python3.6/dist-packages (from catalyst) (4.1.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from catalyst) (19.2)\n",
            "Requirement already satisfied: numpy>=1.16.4 in /usr/local/lib/python3.6/dist-packages (from catalyst) (1.17.3)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.6/dist-packages (from catalyst) (0.9.0)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.6/dist-packages (from catalyst) (5.5.0)\n",
            "Requirement already satisfied: pandas>=0.22 in /usr/local/lib/python3.6/dist-packages (from catalyst) (0.25.3)\n",
            "Collecting tensorboardX\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/5c/e918d9f190baab8d55bad52840d8091dd5114cc99f03eaa6d72d404503cc/tensorboardX-1.9-py2.py3-none-any.whl (190kB)\n",
            "\u001b[K     |████████████████████████████████| 194kB 45.2MB/s \n",
            "\u001b[?25hCollecting safitty>=1.2.3\n",
            "  Downloading https://files.pythonhosted.org/packages/37/ea/51fedb7c8802b09d557a04db13661939bb483f40e1450958961ce50f15d6/safitty-1.3-py3-none-any.whl\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from catalyst) (3.1.1)\n",
            "Collecting GitPython>=2.1.11\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/aa/25/9fd9f0b05408021736a22ae73f837152c132e4ea85cdd71d186e24efec31/GitPython-3.0.4-py3-none-any.whl (454kB)\n",
            "\u001b[K     |████████████████████████████████| 460kB 29.8MB/s \n",
            "\u001b[?25hCollecting crc32c>=1.7\n",
            "  Downloading https://files.pythonhosted.org/packages/65/7f/4b4dc07c8fdd391c5bdf2e91d495bcfe9d8976ce7deb3439c6007c9c3625/crc32c-1.7-cp36-cp36m-manylinux1_x86_64.whl\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.20->catalyst) (0.14.0)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.20->catalyst) (1.3.1)\n",
            "Requirement already satisfied: grpcio>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard->catalyst) (1.15.0)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->catalyst) (3.10.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard->catalyst) (0.16.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->catalyst) (41.4.0)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorboard->catalyst) (0.33.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard->catalyst) (3.1.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->catalyst) (1.12.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.6/dist-packages (from tensorboard->catalyst) (0.8.1)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision>=0.2.1->catalyst) (4.3.0)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.14.2->catalyst) (2.4)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.14.2->catalyst) (1.1.1)\n",
            "Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.6/dist-packages (from plotly>=4.1.0->catalyst) (1.3.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->catalyst) (2.4.4)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from ipython->catalyst) (4.4.1)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from ipython->catalyst) (2.1.3)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.6/dist-packages (from ipython->catalyst) (4.3.3)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython->catalyst) (4.7.0)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython->catalyst) (0.8.1)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from ipython->catalyst) (1.0.18)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython->catalyst) (0.7.5)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.22->catalyst) (2.6.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.22->catalyst) (2018.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catalyst) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catalyst) (0.10.0)\n",
            "Collecting gitdb2>=2.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/03/6c/99296f89bad2ef85626e1df9f677acbee8885bb043ad82ad3ed4746d2325/gitdb2-2.0.6-py2.py3-none-any.whl (63kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 8.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow>=4.1.1->torchvision>=0.2.1->catalyst) (0.46)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.2->ipython->catalyst) (0.2.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.6/dist-packages (from pexpect; sys_platform != \"win32\"->ipython->catalyst) (0.6.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->catalyst) (0.1.7)\n",
            "Collecting smmap2>=2.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/55/d2/866d45e3a121ee15a1dc013824d58072fd5c7799c9c34d01378eb262ca8f/smmap2-2.0.5-py2.py3-none-any.whl\n",
            "Installing collected packages: tqdm, tensorboardX, safitty, smmap2, gitdb2, GitPython, crc32c, catalyst\n",
            "  Found existing installation: tqdm 4.28.1\n",
            "    Uninstalling tqdm-4.28.1:\n",
            "      Successfully uninstalled tqdm-4.28.1\n",
            "Successfully installed GitPython-3.0.4 catalyst-19.11.2 crc32c-1.7 gitdb2-2.0.6 safitty-1.3 smmap2-2.0.5 tensorboardX-1.9 tqdm-4.38.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "tqdm"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Collecting pretrainedmodels\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/84/0e/be6a0e58447ac16c938799d49bfb5fb7a80ac35e137547fc6cee2c08c4cf/pretrainedmodels-0.7.4.tar.gz (58kB)\n",
            "\r\u001b[K     |█████▋                          | 10kB 17.1MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 20kB 2.1MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 30kB 3.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 40kB 2.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 51kB 2.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 61kB 2.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from pretrainedmodels) (1.3.1+cu100)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (from pretrainedmodels) (0.4.2+cu100)\n",
            "Collecting munch\n",
            "  Downloading https://files.pythonhosted.org/packages/cc/ab/85d8da5c9a45e072301beb37ad7f833cd344e04c817d97e0cc75681d248f/munch-2.5.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pretrainedmodels) (4.38.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch->pretrainedmodels) (1.17.3)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision->pretrainedmodels) (4.3.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision->pretrainedmodels) (1.12.0)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow>=4.1.1->torchvision->pretrainedmodels) (0.46)\n",
            "Building wheels for collected packages: pretrainedmodels\n",
            "  Building wheel for pretrainedmodels (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pretrainedmodels: filename=pretrainedmodels-0.7.4-cp36-none-any.whl size=60963 sha256=1b0a906133452158395f3b1241cbc80938bfb1208639bb7b051331697135bcc5\n",
            "  Stored in directory: /root/.cache/pip/wheels/69/df/63/62583c096289713f22db605aa2334de5b591d59861a02c2ecd\n",
            "Successfully built pretrainedmodels\n",
            "Installing collected packages: munch, pretrainedmodels\n",
            "Successfully installed munch-2.5.0 pretrainedmodels-0.7.4\n",
            "Collecting git+https://github.com/qubvel/segmentation_models.pytorch\n",
            "  Cloning https://github.com/qubvel/segmentation_models.pytorch to /tmp/pip-req-build-x_qdhdlh\n",
            "  Running command git clone -q https://github.com/qubvel/segmentation_models.pytorch /tmp/pip-req-build-x_qdhdlh\n",
            "Collecting torchvision<=0.4.0,>=0.2.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/06/e6/a564eba563f7ff53aa7318ff6aaa5bd8385cbda39ed55ba471e95af27d19/torchvision-0.4.0-cp36-cp36m-manylinux1_x86_64.whl (8.8MB)\n",
            "\u001b[K     |████████████████████████████████| 8.8MB 3.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: pretrainedmodels==0.7.4 in /usr/local/lib/python3.6/dist-packages (from segmentation-models-pytorch==0.0.3) (0.7.4)\n",
            "Collecting efficientnet-pytorch==0.4.0\n",
            "  Downloading https://files.pythonhosted.org/packages/12/f8/35453605c6c471fc406a137a894fb381b05ae9f174b2ca4956592512374e/efficientnet_pytorch-0.4.0.tar.gz\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision<=0.4.0,>=0.2.2->segmentation-models-pytorch==0.0.3) (1.17.3)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision<=0.4.0,>=0.2.2->segmentation-models-pytorch==0.0.3) (4.3.0)\n",
            "Collecting torch==1.2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/30/57/d5cceb0799c06733eefce80c395459f28970ebb9e896846ce96ab579a3f1/torch-1.2.0-cp36-cp36m-manylinux1_x86_64.whl (748.8MB)\n",
            "\u001b[K     |████████████████████████████████| 748.9MB 22kB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision<=0.4.0,>=0.2.2->segmentation-models-pytorch==0.0.3) (1.12.0)\n",
            "Requirement already satisfied: munch in /usr/local/lib/python3.6/dist-packages (from pretrainedmodels==0.7.4->segmentation-models-pytorch==0.0.3) (2.5.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pretrainedmodels==0.7.4->segmentation-models-pytorch==0.0.3) (4.38.0)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow>=4.1.1->torchvision<=0.4.0,>=0.2.2->segmentation-models-pytorch==0.0.3) (0.46)\n",
            "Building wheels for collected packages: segmentation-models-pytorch, efficientnet-pytorch\n",
            "  Building wheel for segmentation-models-pytorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for segmentation-models-pytorch: filename=segmentation_models_pytorch-0.0.3-cp36-none-any.whl size=29990 sha256=1363ea9b9d1adb0fc0c7b8b88077b672b0cf5933a3b4300e8b4165550cc41cd3\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-5bg13xie/wheels/79/3f/09/1587a252e0314d26ad242d6d2e165622ab95c95e5cfe4b942c\n",
            "  Building wheel for efficientnet-pytorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for efficientnet-pytorch: filename=efficientnet_pytorch-0.4.0-cp36-none-any.whl size=11149 sha256=da9b4b83d38690519486a5ba95549584fdfea04c6cfca122b652d48a0735a395\n",
            "  Stored in directory: /root/.cache/pip/wheels/27/56/13/5bdaa98ca8bd7d5da65cc741987dd14391b87fa1a09081d17a\n",
            "Successfully built segmentation-models-pytorch efficientnet-pytorch\n",
            "Installing collected packages: torch, torchvision, efficientnet-pytorch, segmentation-models-pytorch\n",
            "  Found existing installation: torch 1.3.1+cu100\n",
            "    Uninstalling torch-1.3.1+cu100:\n",
            "      Successfully uninstalled torch-1.3.1+cu100\n",
            "  Found existing installation: torchvision 0.4.2+cu100\n",
            "    Uninstalling torchvision-0.4.2+cu100:\n",
            "      Successfully uninstalled torchvision-0.4.2+cu100\n",
            "Successfully installed efficientnet-pytorch-0.4.0 segmentation-models-pytorch-0.0.3 torch-1.2.0 torchvision-0.4.0\n",
            "Collecting pytorch_toolbelt\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/30/00/eb830ae0eb3f46751c1927d69e8e9eebd36bf63c2c9d259fcec4eecd5f4e/pytorch_toolbelt-0.2.1.tar.gz (62kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 1.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.1 in /usr/local/lib/python3.6/dist-packages (from pytorch_toolbelt) (1.2.0)\n",
            "Requirement already satisfied: torchvision>=0.3 in /usr/local/lib/python3.6/dist-packages (from pytorch_toolbelt) (0.4.0)\n",
            "Collecting opencv-python>=4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5e/7e/bd5425f4dacb73367fddc71388a47c1ea570839197c2bcad86478e565186/opencv_python-4.1.1.26-cp36-cp36m-manylinux1_x86_64.whl (28.7MB)\n",
            "\u001b[K     |████████████████████████████████| 28.7MB 31.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch>=1.1->pytorch_toolbelt) (1.17.3)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision>=0.3->pytorch_toolbelt) (4.3.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision>=0.3->pytorch_toolbelt) (1.12.0)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow>=4.1.1->torchvision>=0.3->pytorch_toolbelt) (0.46)\n",
            "Building wheels for collected packages: pytorch-toolbelt\n",
            "  Building wheel for pytorch-toolbelt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pytorch-toolbelt: filename=pytorch_toolbelt-0.2.1-cp36-none-any.whl size=77760 sha256=3c5ae8a7b983ce9570a819a1050481a1186f771b1fa692dcbbedac8c794dcc57\n",
            "  Stored in directory: /root/.cache/pip/wheels/51/ea/7c/4aeb4525cb67895638573bf0bdcd92da05a9997bc722febf6f\n",
            "Successfully built pytorch-toolbelt\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: opencv-python, pytorch-toolbelt\n",
            "  Found existing installation: opencv-python 3.4.7.28\n",
            "    Uninstalling opencv-python-3.4.7.28:\n",
            "      Successfully uninstalled opencv-python-3.4.7.28\n",
            "Successfully installed opencv-python-4.1.1.26 pytorch-toolbelt-0.2.1\n",
            "Requirement already satisfied: torchvision==0.4 in /usr/local/lib/python3.6/dist-packages (0.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision==0.4) (1.17.3)\n",
            "Requirement already satisfied: torch==1.2.0 in /usr/local/lib/python3.6/dist-packages (from torchvision==0.4) (1.2.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision==0.4) (1.12.0)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision==0.4) (4.3.0)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow>=4.1.1->torchvision==0.4) (0.46)\n",
            "Collecting albumentations==0.3.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ad/34/e1da4fab7282d732a6cef827c7e5fb1efa1f02c3ba1bff4a0ace2daf6639/albumentations-0.3.2.tar.gz (79kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 2.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from albumentations==0.3.2) (1.17.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from albumentations==0.3.2) (1.3.1)\n",
            "Collecting opencv-python-headless\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1f/dc/b250f03ab68068033fd2356428c1357431d8ebc6a26405098e0f27c94f7a/opencv_python_headless-4.1.1.26-cp36-cp36m-manylinux1_x86_64.whl (22.1MB)\n",
            "\u001b[K     |████████████████████████████████| 22.1MB 37.1MB/s \n",
            "\u001b[?25hCollecting imgaug<0.2.7,>=0.2.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ad/2e/748dbb7bb52ec8667098bae9b585f448569ae520031932687761165419a2/imgaug-0.2.6.tar.gz (631kB)\n",
            "\u001b[K     |████████████████████████████████| 634kB 33.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: PyYAML in /usr/local/lib/python3.6/dist-packages (from albumentations==0.3.2) (3.13)\n",
            "Requirement already satisfied: scikit-image>=0.11.0 in /usr/local/lib/python3.6/dist-packages (from imgaug<0.2.7,>=0.2.5->albumentations==0.3.2) (0.15.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from imgaug<0.2.7,>=0.2.5->albumentations==0.3.2) (1.12.0)\n",
            "Requirement already satisfied: imageio>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations==0.3.2) (2.4.1)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations==0.3.2) (2.4)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations==0.3.2) (1.1.1)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations==0.3.2) (3.1.1)\n",
            "Requirement already satisfied: pillow>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations==0.3.2) (4.3.0)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=2.0->scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations==0.3.2) (4.4.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations==0.3.2) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations==0.3.2) (2.6.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations==0.3.2) (2.4.4)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations==0.3.2) (1.1.0)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow>=4.3.0->scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations==0.3.2) (0.46)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations==0.3.2) (41.4.0)\n",
            "Building wheels for collected packages: albumentations, imgaug\n",
            "  Building wheel for albumentations (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for albumentations: filename=albumentations-0.3.2-cp36-none-any.whl size=51063 sha256=9bd1f27062efb4d38aee3913db2c51c52613d4fe78425b8cd8b9aa2c2f4970f3\n",
            "  Stored in directory: /root/.cache/pip/wheels/4c/74/a9/b8cfb94bcf1a5d7ea53a6b522bcd372b23b64595b7328e4f3f\n",
            "  Building wheel for imgaug (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for imgaug: filename=imgaug-0.2.6-cp36-none-any.whl size=654020 sha256=f70bfd2fbf5f24e597a876e817c3d309bcdbc47917b481986f922dfe6401dc44\n",
            "  Stored in directory: /root/.cache/pip/wheels/97/ec/48/0d25896c417b715af6236dbcef8f0bed136a1a5e52972fc6d0\n",
            "Successfully built albumentations imgaug\n",
            "Installing collected packages: opencv-python-headless, imgaug, albumentations\n",
            "  Found existing installation: imgaug 0.2.9\n",
            "    Uninstalling imgaug-0.2.9:\n",
            "      Successfully uninstalled imgaug-0.2.9\n",
            "  Found existing installation: albumentations 0.1.12\n",
            "    Uninstalling albumentations-0.1.12:\n",
            "      Successfully uninstalled albumentations-0.1.12\n",
            "Successfully installed albumentations-0.3.2 imgaug-0.2.6 opencv-python-headless-4.1.1.26\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vDtD6jPT3aCa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import cv2\n",
        "import collections\n",
        "import time \n",
        "import tqdm\n",
        "from PIL import Image\n",
        "from functools import partial\n",
        "train_on_gpu = True\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader,Dataset\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "from torch.optim.lr_scheduler import StepLR, ReduceLROnPlateau, CosineAnnealingLR\n",
        "\n",
        "import albumentations as albu\n",
        "from albumentations import torch as AT\n",
        "\n",
        "import gc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s_Yw7T7N4Dql",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from catalyst.data import Augmentor\n",
        "from catalyst.dl import utils\n",
        "from catalyst.data.reader import ImageReader, ScalarReader, ReaderCompose, LambdaReader\n",
        "from catalyst.dl.runner import SupervisedRunner\n",
        "from catalyst.contrib.models.segmentation import Unet\n",
        "from catalyst.dl.callbacks import DiceCallback, EarlyStoppingCallback, InferCallback, CheckpointCallback\n",
        "\n",
        "import segmentation_models_pytorch as smp"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uIbeGU-rs7mv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c8e5a06e-6822-4826-daed-475973b67a1c"
      },
      "source": [
        "!pip install -v --no-cache-dir --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" /content/gdrive/My\\ Drive/kaggle_cloud/apex\n",
        "from apex import amp"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pip/_internal/commands/install.py:283: UserWarning: Disabling all use of wheels due to the use of --build-options / --global-options / --install-options.\n",
            "  cmdoptions.check_install_build_global(options)\n",
            "Created temporary directory: /tmp/pip-ephem-wheel-cache-cojtj51e\n",
            "Created temporary directory: /tmp/pip-req-tracker-wtrl8674\n",
            "Created requirements tracker '/tmp/pip-req-tracker-wtrl8674'\n",
            "Created temporary directory: /tmp/pip-install-t419333b\n",
            "Processing ./gdrive/My Drive/kaggle_cloud/apex\n",
            "  Created temporary directory: /tmp/pip-req-build-sqki5bid\n",
            "  Added file:///content/gdrive/My%20Drive/kaggle_cloud/apex to build tracker '/tmp/pip-req-tracker-wtrl8674'\n",
            "    Running setup.py (path:/tmp/pip-req-build-sqki5bid/setup.py) egg_info for package from file:///content/gdrive/My%20Drive/kaggle_cloud/apex\n",
            "    Running command python setup.py egg_info\n",
            "    torch.__version__  =  1.2.0\n",
            "    running egg_info\n",
            "    creating /tmp/pip-req-build-sqki5bid/pip-egg-info/apex.egg-info\n",
            "    writing /tmp/pip-req-build-sqki5bid/pip-egg-info/apex.egg-info/PKG-INFO\n",
            "    writing dependency_links to /tmp/pip-req-build-sqki5bid/pip-egg-info/apex.egg-info/dependency_links.txt\n",
            "    writing top-level names to /tmp/pip-req-build-sqki5bid/pip-egg-info/apex.egg-info/top_level.txt\n",
            "    writing manifest file '/tmp/pip-req-build-sqki5bid/pip-egg-info/apex.egg-info/SOURCES.txt'\n",
            "    writing manifest file '/tmp/pip-req-build-sqki5bid/pip-egg-info/apex.egg-info/SOURCES.txt'\n",
            "    /tmp/pip-req-build-sqki5bid/setup.py:43: UserWarning: Option --pyprof not specified. Not installing PyProf dependencies!\n",
            "      warnings.warn(\"Option --pyprof not specified. Not installing PyProf dependencies!\")\n",
            "  Source in /tmp/pip-req-build-sqki5bid has version 0.1, which satisfies requirement apex==0.1 from file:///content/gdrive/My%20Drive/kaggle_cloud/apex\n",
            "  Removed apex==0.1 from file:///content/gdrive/My%20Drive/kaggle_cloud/apex from build tracker '/tmp/pip-req-tracker-wtrl8674'\n",
            "Skipping wheel build for apex, due to binaries being disabled for it.\n",
            "Installing collected packages: apex\n",
            "  Created temporary directory: /tmp/pip-record-7zhipet4\n",
            "    Running command /usr/bin/python3 -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-req-build-sqki5bid/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-req-build-sqki5bid/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' --cpp_ext --cuda_ext install --record /tmp/pip-record-7zhipet4/install-record.txt --single-version-externally-managed --compile\n",
            "    torch.__version__  =  1.2.0\n",
            "    /tmp/pip-req-build-sqki5bid/setup.py:43: UserWarning: Option --pyprof not specified. Not installing PyProf dependencies!\n",
            "      warnings.warn(\"Option --pyprof not specified. Not installing PyProf dependencies!\")\n",
            "\n",
            "    Compiling cuda extensions with\n",
            "    nvcc: NVIDIA (R) Cuda compiler driver\n",
            "    Copyright (c) 2005-2018 NVIDIA Corporation\n",
            "    Built on Sat_Aug_25_21:08:01_CDT_2018\n",
            "    Cuda compilation tools, release 10.0, V10.0.130\n",
            "    from /usr/local/cuda/bin\n",
            "\n",
            "    running install\n",
            "    running build\n",
            "    running build_py\n",
            "    creating build\n",
            "    creating build/lib.linux-x86_64-3.6\n",
            "    creating build/lib.linux-x86_64-3.6/apex\n",
            "    copying apex/__init__.py -> build/lib.linux-x86_64-3.6/apex\n",
            "    creating build/lib.linux-x86_64-3.6/apex/parallel\n",
            "    copying apex/parallel/optimized_sync_batchnorm.py -> build/lib.linux-x86_64-3.6/apex/parallel\n",
            "    copying apex/parallel/optimized_sync_batchnorm_kernel.py -> build/lib.linux-x86_64-3.6/apex/parallel\n",
            "    copying apex/parallel/distributed.py -> build/lib.linux-x86_64-3.6/apex/parallel\n",
            "    copying apex/parallel/__init__.py -> build/lib.linux-x86_64-3.6/apex/parallel\n",
            "    copying apex/parallel/sync_batchnorm_kernel.py -> build/lib.linux-x86_64-3.6/apex/parallel\n",
            "    copying apex/parallel/sync_batchnorm.py -> build/lib.linux-x86_64-3.6/apex/parallel\n",
            "    copying apex/parallel/LARC.py -> build/lib.linux-x86_64-3.6/apex/parallel\n",
            "    copying apex/parallel/multiproc.py -> build/lib.linux-x86_64-3.6/apex/parallel\n",
            "    creating build/lib.linux-x86_64-3.6/apex/fp16_utils\n",
            "    copying apex/fp16_utils/loss_scaler.py -> build/lib.linux-x86_64-3.6/apex/fp16_utils\n",
            "    copying apex/fp16_utils/fp16util.py -> build/lib.linux-x86_64-3.6/apex/fp16_utils\n",
            "    copying apex/fp16_utils/__init__.py -> build/lib.linux-x86_64-3.6/apex/fp16_utils\n",
            "    copying apex/fp16_utils/fp16_optimizer.py -> build/lib.linux-x86_64-3.6/apex/fp16_utils\n",
            "    creating build/lib.linux-x86_64-3.6/apex/multi_tensor_apply\n",
            "    copying apex/multi_tensor_apply/multi_tensor_apply.py -> build/lib.linux-x86_64-3.6/apex/multi_tensor_apply\n",
            "    copying apex/multi_tensor_apply/__init__.py -> build/lib.linux-x86_64-3.6/apex/multi_tensor_apply\n",
            "    creating build/lib.linux-x86_64-3.6/apex/optimizers\n",
            "    copying apex/optimizers/fused_adam.py -> build/lib.linux-x86_64-3.6/apex/optimizers\n",
            "    copying apex/optimizers/__init__.py -> build/lib.linux-x86_64-3.6/apex/optimizers\n",
            "    copying apex/optimizers/fused_novograd.py -> build/lib.linux-x86_64-3.6/apex/optimizers\n",
            "    copying apex/optimizers/fused_lamb.py -> build/lib.linux-x86_64-3.6/apex/optimizers\n",
            "    copying apex/optimizers/fused_sgd.py -> build/lib.linux-x86_64-3.6/apex/optimizers\n",
            "    creating build/lib.linux-x86_64-3.6/apex/amp\n",
            "    copying apex/amp/_initialize.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
            "    copying apex/amp/_process_optimizer.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
            "    copying apex/amp/utils.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
            "    copying apex/amp/compat.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
            "    copying apex/amp/wrap.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
            "    copying apex/amp/__version__.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
            "    copying apex/amp/frontend.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
            "    copying apex/amp/opt.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
            "    copying apex/amp/scaler.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
            "    copying apex/amp/amp.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
            "    copying apex/amp/rnn_compat.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
            "    copying apex/amp/__init__.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
            "    copying apex/amp/_amp_state.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
            "    copying apex/amp/handle.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
            "    creating build/lib.linux-x86_64-3.6/apex/RNN\n",
            "    copying apex/RNN/RNNBackend.py -> build/lib.linux-x86_64-3.6/apex/RNN\n",
            "    copying apex/RNN/cells.py -> build/lib.linux-x86_64-3.6/apex/RNN\n",
            "    copying apex/RNN/models.py -> build/lib.linux-x86_64-3.6/apex/RNN\n",
            "    copying apex/RNN/__init__.py -> build/lib.linux-x86_64-3.6/apex/RNN\n",
            "    creating build/lib.linux-x86_64-3.6/apex/reparameterization\n",
            "    copying apex/reparameterization/reparameterization.py -> build/lib.linux-x86_64-3.6/apex/reparameterization\n",
            "    copying apex/reparameterization/weight_norm.py -> build/lib.linux-x86_64-3.6/apex/reparameterization\n",
            "    copying apex/reparameterization/__init__.py -> build/lib.linux-x86_64-3.6/apex/reparameterization\n",
            "    creating build/lib.linux-x86_64-3.6/apex/pyprof\n",
            "    copying apex/pyprof/__init__.py -> build/lib.linux-x86_64-3.6/apex/pyprof\n",
            "    creating build/lib.linux-x86_64-3.6/apex/normalization\n",
            "    copying apex/normalization/fused_layer_norm.py -> build/lib.linux-x86_64-3.6/apex/normalization\n",
            "    copying apex/normalization/__init__.py -> build/lib.linux-x86_64-3.6/apex/normalization\n",
            "    creating build/lib.linux-x86_64-3.6/apex/contrib\n",
            "    copying apex/contrib/__init__.py -> build/lib.linux-x86_64-3.6/apex/contrib\n",
            "    creating build/lib.linux-x86_64-3.6/apex/amp/lists\n",
            "    copying apex/amp/lists/torch_overrides.py -> build/lib.linux-x86_64-3.6/apex/amp/lists\n",
            "    copying apex/amp/lists/tensor_overrides.py -> build/lib.linux-x86_64-3.6/apex/amp/lists\n",
            "    copying apex/amp/lists/__init__.py -> build/lib.linux-x86_64-3.6/apex/amp/lists\n",
            "    copying apex/amp/lists/functional_overrides.py -> build/lib.linux-x86_64-3.6/apex/amp/lists\n",
            "    creating build/lib.linux-x86_64-3.6/apex/pyprof/parse\n",
            "    copying apex/pyprof/parse/kernel.py -> build/lib.linux-x86_64-3.6/apex/pyprof/parse\n",
            "    copying apex/pyprof/parse/parse.py -> build/lib.linux-x86_64-3.6/apex/pyprof/parse\n",
            "    copying apex/pyprof/parse/__init__.py -> build/lib.linux-x86_64-3.6/apex/pyprof/parse\n",
            "    copying apex/pyprof/parse/nvvp.py -> build/lib.linux-x86_64-3.6/apex/pyprof/parse\n",
            "    copying apex/pyprof/parse/__main__.py -> build/lib.linux-x86_64-3.6/apex/pyprof/parse\n",
            "    copying apex/pyprof/parse/db.py -> build/lib.linux-x86_64-3.6/apex/pyprof/parse\n",
            "    creating build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/misc.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/blas.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/index_slice_join_mutate.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/prof.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/normalization.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/linear.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/pointwise.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/data.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/embedding.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/activation.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/recurrentCell.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/base.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/output.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/conv.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/optim.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/randomSample.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/softmax.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/utility.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/__init__.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/loss.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/dropout.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/__main__.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/reduction.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/usage.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/pooling.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/convert.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    creating build/lib.linux-x86_64-3.6/apex/pyprof/nvtx\n",
            "    copying apex/pyprof/nvtx/__init__.py -> build/lib.linux-x86_64-3.6/apex/pyprof/nvtx\n",
            "    copying apex/pyprof/nvtx/nvmarker.py -> build/lib.linux-x86_64-3.6/apex/pyprof/nvtx\n",
            "    creating build/lib.linux-x86_64-3.6/apex/contrib/optimizers\n",
            "    copying apex/contrib/optimizers/fused_adam.py -> build/lib.linux-x86_64-3.6/apex/contrib/optimizers\n",
            "    copying apex/contrib/optimizers/__init__.py -> build/lib.linux-x86_64-3.6/apex/contrib/optimizers\n",
            "    copying apex/contrib/optimizers/fp16_optimizer.py -> build/lib.linux-x86_64-3.6/apex/contrib/optimizers\n",
            "    creating build/lib.linux-x86_64-3.6/apex/contrib/xentropy\n",
            "    copying apex/contrib/xentropy/softmax_xentropy.py -> build/lib.linux-x86_64-3.6/apex/contrib/xentropy\n",
            "    copying apex/contrib/xentropy/__init__.py -> build/lib.linux-x86_64-3.6/apex/contrib/xentropy\n",
            "    creating build/lib.linux-x86_64-3.6/apex/contrib/groupbn\n",
            "    copying apex/contrib/groupbn/__init__.py -> build/lib.linux-x86_64-3.6/apex/contrib/groupbn\n",
            "    copying apex/contrib/groupbn/batch_norm.py -> build/lib.linux-x86_64-3.6/apex/contrib/groupbn\n",
            "    running build_ext\n",
            "    building 'apex_C' extension\n",
            "    creating build/temp.linux-x86_64-3.6\n",
            "    creating build/temp.linux-x86_64-3.6/csrc\n",
            "    x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/include/python3.6m -c csrc/flatten_unflatten.cpp -o build/temp.linux-x86_64-3.6/csrc/flatten_unflatten.o -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=apex_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
            "    x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/csrc/flatten_unflatten.o -o build/lib.linux-x86_64-3.6/apex_C.cpython-36m-x86_64-linux-gnu.so\n",
            "    building 'amp_C' extension\n",
            "    x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/amp_C_frontend.cpp -o build/temp.linux-x86_64-3.6/csrc/amp_C_frontend.o -O3 -DVERSION_GE_1_1 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
            "    /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/multi_tensor_sgd_kernel.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_sgd_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
            "    /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/multi_tensor_scale_kernel.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_scale_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
            "    /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/multi_tensor_axpby_kernel.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_axpby_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
            "    /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/multi_tensor_l2norm_kernel.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_l2norm_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
            "    /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/multi_tensor_lamb_stage_1.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_lamb_stage_1.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
            "    /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/multi_tensor_lamb_stage_2.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_lamb_stage_2.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
            "    /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/multi_tensor_adam.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_adam.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
            "    /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/multi_tensor_novograd.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_novograd.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
            "    /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/multi_tensor_lamb.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_lamb.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
            "    x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/csrc/amp_C_frontend.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_sgd_kernel.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_scale_kernel.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_axpby_kernel.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_l2norm_kernel.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_lamb_stage_1.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_lamb_stage_2.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_adam.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_novograd.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_lamb.o -L/usr/local/cuda/lib64 -lcudart -o build/lib.linux-x86_64-3.6/amp_C.cpython-36m-x86_64-linux-gnu.so\n",
            "    building 'syncbn' extension\n",
            "    x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/syncbn.cpp -o build/temp.linux-x86_64-3.6/csrc/syncbn.o -O3 -DVERSION_GE_1_1 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=syncbn -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
            "    /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/welford.cu -o build/temp.linux-x86_64-3.6/csrc/welford.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -O3 -DVERSION_GE_1_1 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=syncbn -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
            "    x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/csrc/syncbn.o build/temp.linux-x86_64-3.6/csrc/welford.o -L/usr/local/cuda/lib64 -lcudart -o build/lib.linux-x86_64-3.6/syncbn.cpython-36m-x86_64-linux-gnu.so\n",
            "    building 'fused_layer_norm_cuda' extension\n",
            "    x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/layer_norm_cuda.cpp -o build/temp.linux-x86_64-3.6/csrc/layer_norm_cuda.o -O3 -DVERSION_GE_1_1 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=fused_layer_norm_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
            "    /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/layer_norm_cuda_kernel.cu -o build/temp.linux-x86_64-3.6/csrc/layer_norm_cuda_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -maxrregcount=50 -O3 --use_fast_math -DVERSION_GE_1_1 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=fused_layer_norm_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
            "    x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/csrc/layer_norm_cuda.o build/temp.linux-x86_64-3.6/csrc/layer_norm_cuda_kernel.o -L/usr/local/cuda/lib64 -lcudart -o build/lib.linux-x86_64-3.6/fused_layer_norm_cuda.cpython-36m-x86_64-linux-gnu.so\n",
            "    running install_lib\n",
            "    copying build/lib.linux-x86_64-3.6/syncbn.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/dist-packages\n",
            "    creating /usr/local/lib/python3.6/dist-packages/apex\n",
            "    creating /usr/local/lib/python3.6/dist-packages/apex/parallel\n",
            "    copying build/lib.linux-x86_64-3.6/apex/parallel/optimized_sync_batchnorm.py -> /usr/local/lib/python3.6/dist-packages/apex/parallel\n",
            "    copying build/lib.linux-x86_64-3.6/apex/parallel/optimized_sync_batchnorm_kernel.py -> /usr/local/lib/python3.6/dist-packages/apex/parallel\n",
            "    copying build/lib.linux-x86_64-3.6/apex/parallel/distributed.py -> /usr/local/lib/python3.6/dist-packages/apex/parallel\n",
            "    copying build/lib.linux-x86_64-3.6/apex/parallel/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/parallel\n",
            "    copying build/lib.linux-x86_64-3.6/apex/parallel/sync_batchnorm_kernel.py -> /usr/local/lib/python3.6/dist-packages/apex/parallel\n",
            "    copying build/lib.linux-x86_64-3.6/apex/parallel/sync_batchnorm.py -> /usr/local/lib/python3.6/dist-packages/apex/parallel\n",
            "    copying build/lib.linux-x86_64-3.6/apex/parallel/LARC.py -> /usr/local/lib/python3.6/dist-packages/apex/parallel\n",
            "    copying build/lib.linux-x86_64-3.6/apex/parallel/multiproc.py -> /usr/local/lib/python3.6/dist-packages/apex/parallel\n",
            "    creating /usr/local/lib/python3.6/dist-packages/apex/fp16_utils\n",
            "    copying build/lib.linux-x86_64-3.6/apex/fp16_utils/loss_scaler.py -> /usr/local/lib/python3.6/dist-packages/apex/fp16_utils\n",
            "    copying build/lib.linux-x86_64-3.6/apex/fp16_utils/fp16util.py -> /usr/local/lib/python3.6/dist-packages/apex/fp16_utils\n",
            "    copying build/lib.linux-x86_64-3.6/apex/fp16_utils/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/fp16_utils\n",
            "    copying build/lib.linux-x86_64-3.6/apex/fp16_utils/fp16_optimizer.py -> /usr/local/lib/python3.6/dist-packages/apex/fp16_utils\n",
            "    creating /usr/local/lib/python3.6/dist-packages/apex/multi_tensor_apply\n",
            "    copying build/lib.linux-x86_64-3.6/apex/multi_tensor_apply/multi_tensor_apply.py -> /usr/local/lib/python3.6/dist-packages/apex/multi_tensor_apply\n",
            "    copying build/lib.linux-x86_64-3.6/apex/multi_tensor_apply/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/multi_tensor_apply\n",
            "    creating /usr/local/lib/python3.6/dist-packages/apex/optimizers\n",
            "    copying build/lib.linux-x86_64-3.6/apex/optimizers/fused_adam.py -> /usr/local/lib/python3.6/dist-packages/apex/optimizers\n",
            "    copying build/lib.linux-x86_64-3.6/apex/optimizers/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/optimizers\n",
            "    copying build/lib.linux-x86_64-3.6/apex/optimizers/fused_novograd.py -> /usr/local/lib/python3.6/dist-packages/apex/optimizers\n",
            "    copying build/lib.linux-x86_64-3.6/apex/optimizers/fused_lamb.py -> /usr/local/lib/python3.6/dist-packages/apex/optimizers\n",
            "    copying build/lib.linux-x86_64-3.6/apex/optimizers/fused_sgd.py -> /usr/local/lib/python3.6/dist-packages/apex/optimizers\n",
            "    creating /usr/local/lib/python3.6/dist-packages/apex/amp\n",
            "    copying build/lib.linux-x86_64-3.6/apex/amp/_initialize.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
            "    copying build/lib.linux-x86_64-3.6/apex/amp/_process_optimizer.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
            "    copying build/lib.linux-x86_64-3.6/apex/amp/utils.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
            "    copying build/lib.linux-x86_64-3.6/apex/amp/compat.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
            "    copying build/lib.linux-x86_64-3.6/apex/amp/wrap.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
            "    copying build/lib.linux-x86_64-3.6/apex/amp/__version__.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
            "    copying build/lib.linux-x86_64-3.6/apex/amp/frontend.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
            "    copying build/lib.linux-x86_64-3.6/apex/amp/opt.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
            "    copying build/lib.linux-x86_64-3.6/apex/amp/scaler.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
            "    copying build/lib.linux-x86_64-3.6/apex/amp/amp.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
            "    copying build/lib.linux-x86_64-3.6/apex/amp/rnn_compat.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
            "    copying build/lib.linux-x86_64-3.6/apex/amp/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
            "    creating /usr/local/lib/python3.6/dist-packages/apex/amp/lists\n",
            "    copying build/lib.linux-x86_64-3.6/apex/amp/lists/torch_overrides.py -> /usr/local/lib/python3.6/dist-packages/apex/amp/lists\n",
            "    copying build/lib.linux-x86_64-3.6/apex/amp/lists/tensor_overrides.py -> /usr/local/lib/python3.6/dist-packages/apex/amp/lists\n",
            "    copying build/lib.linux-x86_64-3.6/apex/amp/lists/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/amp/lists\n",
            "    copying build/lib.linux-x86_64-3.6/apex/amp/lists/functional_overrides.py -> /usr/local/lib/python3.6/dist-packages/apex/amp/lists\n",
            "    copying build/lib.linux-x86_64-3.6/apex/amp/_amp_state.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
            "    copying build/lib.linux-x86_64-3.6/apex/amp/handle.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
            "    creating /usr/local/lib/python3.6/dist-packages/apex/RNN\n",
            "    copying build/lib.linux-x86_64-3.6/apex/RNN/RNNBackend.py -> /usr/local/lib/python3.6/dist-packages/apex/RNN\n",
            "    copying build/lib.linux-x86_64-3.6/apex/RNN/cells.py -> /usr/local/lib/python3.6/dist-packages/apex/RNN\n",
            "    copying build/lib.linux-x86_64-3.6/apex/RNN/models.py -> /usr/local/lib/python3.6/dist-packages/apex/RNN\n",
            "    copying build/lib.linux-x86_64-3.6/apex/RNN/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/RNN\n",
            "    creating /usr/local/lib/python3.6/dist-packages/apex/reparameterization\n",
            "    copying build/lib.linux-x86_64-3.6/apex/reparameterization/reparameterization.py -> /usr/local/lib/python3.6/dist-packages/apex/reparameterization\n",
            "    copying build/lib.linux-x86_64-3.6/apex/reparameterization/weight_norm.py -> /usr/local/lib/python3.6/dist-packages/apex/reparameterization\n",
            "    copying build/lib.linux-x86_64-3.6/apex/reparameterization/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/reparameterization\n",
            "    copying build/lib.linux-x86_64-3.6/apex/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex\n",
            "    creating /usr/local/lib/python3.6/dist-packages/apex/pyprof\n",
            "    creating /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/parse/kernel.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/parse/parse.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/parse/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/parse/nvvp.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/parse/__main__.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/parse/db.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof\n",
            "    creating /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/misc.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/blas.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/index_slice_join_mutate.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/prof.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/normalization.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/linear.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/pointwise.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/data.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/embedding.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/activation.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/recurrentCell.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/base.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/output.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/conv.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/optim.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/randomSample.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/softmax.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/utility.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/loss.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/dropout.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/__main__.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/reduction.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/usage.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/pooling.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/convert.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    creating /usr/local/lib/python3.6/dist-packages/apex/pyprof/nvtx\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/nvtx/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/nvtx\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/nvtx/nvmarker.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/nvtx\n",
            "    creating /usr/local/lib/python3.6/dist-packages/apex/normalization\n",
            "    copying build/lib.linux-x86_64-3.6/apex/normalization/fused_layer_norm.py -> /usr/local/lib/python3.6/dist-packages/apex/normalization\n",
            "    copying build/lib.linux-x86_64-3.6/apex/normalization/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/normalization\n",
            "    creating /usr/local/lib/python3.6/dist-packages/apex/contrib\n",
            "    creating /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/optimizers/fused_adam.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/optimizers/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/optimizers/fp16_optimizer.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers\n",
            "    creating /usr/local/lib/python3.6/dist-packages/apex/contrib/xentropy\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/xentropy/softmax_xentropy.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/xentropy\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/xentropy/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/xentropy\n",
            "    creating /usr/local/lib/python3.6/dist-packages/apex/contrib/groupbn\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/groupbn/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/groupbn\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/groupbn/batch_norm.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/groupbn\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib\n",
            "    copying build/lib.linux-x86_64-3.6/amp_C.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/dist-packages\n",
            "    copying build/lib.linux-x86_64-3.6/apex_C.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/dist-packages\n",
            "    copying build/lib.linux-x86_64-3.6/fused_layer_norm_cuda.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/dist-packages\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/parallel/optimized_sync_batchnorm.py to optimized_sync_batchnorm.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/parallel/optimized_sync_batchnorm_kernel.py to optimized_sync_batchnorm_kernel.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/parallel/distributed.py to distributed.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/parallel/__init__.py to __init__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/parallel/sync_batchnorm_kernel.py to sync_batchnorm_kernel.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/parallel/sync_batchnorm.py to sync_batchnorm.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/parallel/LARC.py to LARC.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/parallel/multiproc.py to multiproc.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/fp16_utils/loss_scaler.py to loss_scaler.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/fp16_utils/fp16util.py to fp16util.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/fp16_utils/__init__.py to __init__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/fp16_utils/fp16_optimizer.py to fp16_optimizer.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/multi_tensor_apply/multi_tensor_apply.py to multi_tensor_apply.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/multi_tensor_apply/__init__.py to __init__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/optimizers/fused_adam.py to fused_adam.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/optimizers/__init__.py to __init__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/optimizers/fused_novograd.py to fused_novograd.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/optimizers/fused_lamb.py to fused_lamb.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/optimizers/fused_sgd.py to fused_sgd.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/_initialize.py to _initialize.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/_process_optimizer.py to _process_optimizer.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/utils.py to utils.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/compat.py to compat.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/wrap.py to wrap.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/__version__.py to __version__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/frontend.py to frontend.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/opt.py to opt.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/scaler.py to scaler.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/amp.py to amp.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/rnn_compat.py to rnn_compat.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/__init__.py to __init__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/lists/torch_overrides.py to torch_overrides.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/lists/tensor_overrides.py to tensor_overrides.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/lists/__init__.py to __init__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/lists/functional_overrides.py to functional_overrides.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/_amp_state.py to _amp_state.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/handle.py to handle.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/RNN/RNNBackend.py to RNNBackend.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/RNN/cells.py to cells.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/RNN/models.py to models.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/RNN/__init__.py to __init__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/reparameterization/reparameterization.py to reparameterization.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/reparameterization/weight_norm.py to weight_norm.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/reparameterization/__init__.py to __init__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/__init__.py to __init__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse/kernel.py to kernel.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse/parse.py to parse.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse/__init__.py to __init__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse/nvvp.py to nvvp.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse/__main__.py to __main__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse/db.py to db.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/__init__.py to __init__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/misc.py to misc.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/blas.py to blas.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/index_slice_join_mutate.py to index_slice_join_mutate.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/prof.py to prof.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/normalization.py to normalization.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/linear.py to linear.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/pointwise.py to pointwise.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/data.py to data.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/embedding.py to embedding.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/activation.py to activation.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/recurrentCell.py to recurrentCell.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/base.py to base.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/output.py to output.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/conv.py to conv.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/optim.py to optim.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/randomSample.py to randomSample.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/softmax.py to softmax.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/utility.py to utility.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/__init__.py to __init__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/loss.py to loss.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/dropout.py to dropout.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/__main__.py to __main__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/reduction.py to reduction.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/usage.py to usage.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/pooling.py to pooling.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/convert.py to convert.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/nvtx/__init__.py to __init__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/nvtx/nvmarker.py to nvmarker.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/normalization/fused_layer_norm.py to fused_layer_norm.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/normalization/__init__.py to __init__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers/fused_adam.py to fused_adam.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers/__init__.py to __init__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers/fp16_optimizer.py to fp16_optimizer.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/xentropy/softmax_xentropy.py to softmax_xentropy.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/xentropy/__init__.py to __init__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/groupbn/__init__.py to __init__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/groupbn/batch_norm.py to batch_norm.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/__init__.py to __init__.cpython-36.pyc\n",
            "    running install_egg_info\n",
            "    running egg_info\n",
            "    creating apex.egg-info\n",
            "    writing apex.egg-info/PKG-INFO\n",
            "    writing dependency_links to apex.egg-info/dependency_links.txt\n",
            "    writing top-level names to apex.egg-info/top_level.txt\n",
            "    writing manifest file 'apex.egg-info/SOURCES.txt'\n",
            "    writing manifest file 'apex.egg-info/SOURCES.txt'\n",
            "    Copying apex.egg-info to /usr/local/lib/python3.6/dist-packages/apex-0.1-py3.6.egg-info\n",
            "    running install_scripts\n",
            "    writing list of installed files to '/tmp/pip-record-7zhipet4/install-record.txt'\n",
            "    Running setup.py install for apex ... \u001b[?25l\u001b[?25hdone\n",
            "  Removing source in /tmp/pip-req-build-sqki5bid\n",
            "Successfully installed apex-0.1\n",
            "Cleaning up...\n",
            "Removed build tracker '/tmp/pip-req-tracker-wtrl8674'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WdgtkS7H7J1G",
        "colab_type": "text"
      },
      "source": [
        "# Mount the google drive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xlTlA8EZI4Ds",
        "colab_type": "text"
      },
      "source": [
        "# Helper Functions\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JEQmbzQZ78Ls",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_img(x, folder: str='train_images'):\n",
        "    \"\"\"\n",
        "    Return image based on image name and folder.\n",
        "    \"\"\"\n",
        "    data_folder = f\"{path}/{folder}\"\n",
        "    image_path = os.path.join(data_folder, x)\n",
        "    img = cv2.imread(image_path)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    return img\n",
        "\n",
        "\n",
        "def rle_decode(mask_rle: str = '', shape: tuple = (1400, 2100)):\n",
        "    '''\n",
        "    Decode rle encoded mask.\n",
        "    \n",
        "    :param mask_rle: run-length as string formatted (start length)\n",
        "    :param shape: (height, width) of array to return \n",
        "    Returns numpy array, 1 - mask, 0 - background\n",
        "    '''\n",
        "    s = mask_rle.split()\n",
        "    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n",
        "    starts -= 1\n",
        "    ends = starts + lengths\n",
        "    img = np.zeros(shape[0] * shape[1], dtype=np.uint8)\n",
        "    for lo, hi in zip(starts, ends):\n",
        "        img[lo:hi] = 1\n",
        "    return img.reshape(shape, order='F')\n",
        "\n",
        "\n",
        "def make_mask(df: pd.DataFrame, image_name: str='img.jpg', shape: tuple = (1400, 2100)):\n",
        "    \"\"\"\n",
        "    Create mask based on df, image name and shape.\n",
        "\n",
        "    [OUTPUTS]:\n",
        "    masks: an array with shape (shape[0], shape[1], 4).\n",
        "      Mask for each class labels.\n",
        "    \"\"\"\n",
        "    encoded_masks = df.loc[df['im_id'] == image_name, 'EncodedPixels']\n",
        "    masks = np.zeros((shape[0], shape[1], 4), dtype=np.float32)\n",
        "\n",
        "    for idx, label in enumerate(encoded_masks.values):\n",
        "        if label is not np.nan:\n",
        "            mask = rle_decode(label)\n",
        "            masks[:, :, idx] = mask\n",
        "            \n",
        "    return masks\n",
        "\n",
        "\n",
        "def to_tensor(x, **kwargs):\n",
        "    \"\"\"\n",
        "    Convert image or mask.\n",
        "    \"\"\"\n",
        "    return x.transpose(2, 0, 1).astype('float32')\n",
        "\n",
        "\n",
        "def mask2rle(img):\n",
        "    '''\n",
        "    Convert mask to rle.\n",
        "    img: numpy array, 1 - mask, 0 - background\n",
        "    Returns run length as string formated\n",
        "    '''\n",
        "    pixels= img.T.flatten()\n",
        "    pixels = np.concatenate([[0], pixels, [0]])\n",
        "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
        "    runs[1::2] -= runs[::2]\n",
        "    return ' '.join(str(x) for x in runs)\n",
        "\n",
        "\n",
        "def visualize(image, mask, original_image=None, original_mask=None):\n",
        "    \"\"\"\n",
        "    Plot image and masks.\n",
        "    If two pairs of images and masks are passes, show both.\n",
        "    \"\"\"\n",
        "    fontsize = 14\n",
        "    class_dict = {0: 'Fish', 1: 'Flower', 2: 'Gravel', 3: 'Sugar'}\n",
        "    \n",
        "    if original_image is None and original_mask is None:\n",
        "        f, ax = plt.subplots(1, 5, figsize=(24, 24))\n",
        "\n",
        "        ax[0].imshow(image)\n",
        "        for i in range(4):\n",
        "            ax[i + 1].imshow(mask[:, :, i])\n",
        "            ax[i + 1].set_title(f'Mask {class_dict[i]}', fontsize=fontsize)\n",
        "    else:\n",
        "        f, ax = plt.subplots(2, 5, figsize=(24, 12))\n",
        "\n",
        "        ax[0, 0].imshow(original_image)\n",
        "        ax[0, 0].set_title('Original image', fontsize=fontsize)\n",
        "                \n",
        "        for i in range(4):\n",
        "            ax[0, i + 1].imshow(original_mask[:, :, i])\n",
        "            ax[0, i + 1].set_title(f'Original mask {class_dict[i]}', fontsize=fontsize)\n",
        "        \n",
        "        ax[1, 0].imshow(image)\n",
        "        ax[1, 0].set_title('Transformed image', fontsize=fontsize)\n",
        "        \n",
        "        \n",
        "        for i in range(4):\n",
        "            ax[1, i + 1].imshow(mask[:, :, i])\n",
        "            ax[1, i + 1].set_title(f'Transformed mask {class_dict[i]}', fontsize=fontsize)\n",
        "            \n",
        "            \n",
        "def visualize_with_raw(image, mask, original_image=None, original_mask=None, raw_image=None, raw_mask=None):\n",
        "    \"\"\"\n",
        "    Plot image and masks.\n",
        "    If two pairs of images and masks are passes, show both.\n",
        "    \"\"\"\n",
        "    fontsize = 14\n",
        "    class_dict = {0: 'Fish', 1: 'Flower', 2: 'Gravel', 3: 'Sugar'}\n",
        "\n",
        "    f, ax = plt.subplots(3, 5, figsize=(24, 12))\n",
        "\n",
        "    ax[0, 0].imshow(original_image)\n",
        "    ax[0, 0].set_title('Original image', fontsize=fontsize)\n",
        "\n",
        "    for i in range(4):\n",
        "        ax[0, i + 1].imshow(original_mask[:, :, i])\n",
        "        ax[0, i + 1].set_title(f'Original mask {class_dict[i]}', fontsize=fontsize)\n",
        "\n",
        "\n",
        "    ax[1, 0].imshow(raw_image)\n",
        "    ax[1, 0].set_title('Original image', fontsize=fontsize)\n",
        "\n",
        "    for i in range(4):\n",
        "        ax[1, i + 1].imshow(raw_mask[:, :, i])\n",
        "        ax[1, i + 1].set_title(f'Raw predicted mask {class_dict[i]}', fontsize=fontsize)\n",
        "        \n",
        "    ax[2, 0].imshow(image)\n",
        "    ax[2, 0].set_title('Transformed image', fontsize=fontsize)\n",
        "\n",
        "\n",
        "    for i in range(4):\n",
        "        ax[2, i + 1].imshow(mask[:, :, i])\n",
        "        ax[2, i + 1].set_title(f'Predicted mask with processing {class_dict[i]}', fontsize=fontsize)\n",
        "            \n",
        "            \n",
        "def plot_with_augmentation(image, mask, augment):\n",
        "    \"\"\"\n",
        "    Wrapper for `visualize` function.\n",
        "    \"\"\"\n",
        "    augmented = augment(image=image, mask=mask)\n",
        "    image_flipped = augmented['image']\n",
        "    mask_flipped = augmented['mask']\n",
        "    visualize(image_flipped, mask_flipped, original_image=image, original_mask=mask)\n",
        "\n",
        "  \n",
        "    \n",
        "sigmoid = lambda x: 1 / (1 + np.exp(-x))\n",
        "\n",
        "\n",
        "def post_process(probability, threshold, min_size):\n",
        "    \"\"\"\n",
        "    Post processing of each predicted mask, components with lesser number of pixels\n",
        "    than `min_size` are ignored\n",
        "    \"\"\"\n",
        "    # don't remember where I saw it\n",
        "    mask = cv2.threshold(probability, threshold, 1, cv2.THRESH_BINARY)[1]\n",
        "    num_component, component = cv2.connectedComponents(mask.astype(np.uint8))\n",
        "    predictions = np.zeros((350, 525), np.float32)\n",
        "    num = 0\n",
        "    for c in range(1, num_component):\n",
        "        p = (component == c)\n",
        "        if p.sum() > min_size:\n",
        "            predictions[p] = 1\n",
        "            num += 1\n",
        "    return predictions, num\n",
        "\n",
        "\n",
        "def get_training_augmentation():\n",
        "    \"\"\"\n",
        "    Define the preprocessing for the training data. \n",
        "    \"\"\"\n",
        "    train_transform = [\n",
        "        albu.HorizontalFlip(p=0.5),\n",
        "        albu.ShiftScaleRotate(scale_limit=0.5, rotate_limit=0, shift_limit=0.1, p=0.5, border_mode=0),\n",
        "        albu.GridDistortion(p=0.5),\n",
        "        albu.OpticalDistortion(p=0.5, distort_limit=2, shift_limit=0.5),\n",
        "        albu.Resize(320, 640)\n",
        "    ]\n",
        "    return albu.Compose(train_transform)\n",
        "\n",
        "\n",
        "def get_validation_augmentation():\n",
        "    \"\"\"Add paddings to make image shape divisible by 32\"\"\"\n",
        "    test_transform = [\n",
        "        albu.Resize(320, 640)\n",
        "    ]\n",
        "    return albu.Compose(test_transform)\n",
        "\n",
        "\n",
        "def get_preprocessing(preprocessing_fn):\n",
        "    \"\"\"Construct preprocessing transform\n",
        "    \n",
        "    Args:\n",
        "        preprocessing_fn (callbale): data normalization function \n",
        "            (can be specific for each pretrained neural network)\n",
        "    Return:\n",
        "        transform: albumentations.Compose\n",
        "    \n",
        "    \"\"\"\n",
        "    \n",
        "    _transform = [\n",
        "        albu.augmentations.transforms.Lambda(image=preprocessing_fn),\n",
        "        albu.augmentations.transforms.Lambda(image=to_tensor, mask=to_tensor),\n",
        "    ]\n",
        "    return albu.Compose(_transform)\n",
        "\n",
        "\n",
        "def dice(img1, img2):\n",
        "    img1 = np.asarray(img1).astype(np.bool)\n",
        "    img2 = np.asarray(img2).astype(np.bool)\n",
        "\n",
        "    intersection = np.logical_and(img1, img2)\n",
        "\n",
        "    return 2. * intersection.sum() / (img1.sum() + img2.sum())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pr4oyR37Ke2Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path = '/content/gdrive/My Drive/kaggle_cloud/data'\n",
        "\n",
        "\n",
        "def get_data(path, n_samples=None):\n",
        "  \"\"\"\n",
        "  Read the taining data information, including image id and labels. \n",
        "  \"\"\"\n",
        "  train = pd.read_csv(f'{path}/train.csv')\n",
        "  sub = pd.read_csv(f'{path}/sample_submission.csv')\n",
        "  print(\"Reading the training csv...\")\n",
        "  print(train.columns)\n",
        "  print(train.shape)\n",
        "\n",
        "  n_train = len(os.listdir(f'{path}/train_images'))\n",
        "  print(\"Reading the training images...\")\n",
        "  print(f'There are {n_train} images in the original train dataset')\n",
        "\n",
        "  if n_samples: \n",
        "    train = train.iloc[:n_samples, :]\n",
        "    print(f'Use {n_samples} images within the training dataset.')\n",
        "\n",
        "\n",
        "  train['label'] = train['Image_Label'].apply(lambda x: x.split('_')[1])\n",
        "  train['im_id'] = train['Image_Label'].apply(lambda x: x.split('_')[0])\n",
        "\n",
        "  sub['label'] = sub['Image_Label'].apply(lambda x: x.split('_')[1])\n",
        "  sub['im_id'] = sub['Image_Label'].apply(lambda x: x.split('_')[0])\n",
        "\n",
        "  return train, sub\n",
        "\n",
        "\n",
        "def display_images_with_masks(path, train):\n",
        "  \"\"\"\n",
        "  Randomly choose 4 images from the training dataset, and plot them with the masks.\n",
        "  \"\"\"\n",
        "\n",
        "  fig = plt.figure(figsize=(25, 16))\n",
        "  for j, im_id in enumerate(np.random.choice(train['im_id'].unique(), 4)):\n",
        "      for i, (idx, row) in enumerate(train.loc[train['im_id'] == im_id].iterrows()):\n",
        "          ax = fig.add_subplot(5, 4, j * 4 + i + 1, xticks=[], yticks=[])\n",
        "          im = Image.open(f\"{path}/train_images/{row['Image_Label'].split('_')[0]}\")\n",
        "          plt.imshow(im)\n",
        "          mask_rle = row['EncodedPixels']\n",
        "          try: # label might not be there!\n",
        "              mask = rle_decode(mask_rle)\n",
        "          except:\n",
        "              mask = np.zeros((1400, 2100))\n",
        "          plt.imshow(mask, alpha=0.5, cmap='gray')\n",
        "          ax.set_title(f\"Image: {row['Image_Label'].split('_')[0]}. Label: {row['label']}\")\n",
        "\n",
        "\n",
        "def split_data(train, sub):\n",
        "  \"\"\"\n",
        "  Split the training dataset into train/valid datasets, and use all the data in \n",
        "  the submission dataset as test data. \n",
        "\n",
        "  [OUTPUTS]:\n",
        "  train_ids/valid_ids/test_ids: array of image ids(str). \n",
        "  \"\"\"\n",
        "  train_labels = train.loc[train['EncodedPixels'].isnull() == False, 'Image_Label']\n",
        "  id_mask_count = train_labels.apply(lambda x: x.split('_')[0]).value_counts()\n",
        "  id_mask_count = id_mask_count.reset_index().rename(columns={'index': 'img_id', 'Image_Label': 'count'})\n",
        "  train_ids, valid_ids = train_test_split(id_mask_count['img_id'].values,\n",
        "                                          random_state=42,\n",
        "                                          stratify=id_mask_count['count'],\n",
        "                                          test_size=0.1)\n",
        " \n",
        "  # Alternatively, we can use sub['im_id'] directly. \n",
        "  test_ids = sub['Image_Label'].apply(lambda x: x.split('_')[0]).drop_duplicates().values\n",
        "  \n",
        "  return train_ids, valid_ids, test_ids\n",
        "\n",
        "\n",
        "class CloudDataset(Dataset):\n",
        "    def __init__(self, df: pd.DataFrame = None, datatype: str = 'train', img_ids: np.array = None,\n",
        "                 transforms = albu.Compose([albu.HorizontalFlip(),AT.ToTensor()]),\n",
        "                 preprocessing=None):\n",
        "        \"\"\"\n",
        "        [INPUTS]:\n",
        "        df: a pandas dataframe. \n",
        "          The image information dataframe, obtained from function \"get_data()\".\n",
        "        datatype: string. \n",
        "          Whether it is 'train' or 'test'. \n",
        "        \n",
        "        \"\"\"\n",
        "        self.df = df\n",
        "        if datatype != 'test':\n",
        "            self.data_folder = f\"{path}/train_images\"\n",
        "        else:\n",
        "            self.data_folder = f\"{path}/test_images\"\n",
        "        self.img_ids = img_ids\n",
        "        self.transforms = transforms\n",
        "        self.preprocessing = preprocessing\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_name = self.img_ids[idx]\n",
        "        mask = make_mask(self.df, image_name)\n",
        "        image_path = os.path.join(self.data_folder, image_name)\n",
        "        img = cv2.imread(image_path)\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        augmented = self.transforms(image=img, mask=mask)\n",
        "        img = augmented['image']\n",
        "        mask = augmented['mask']\n",
        "        if self.preprocessing:\n",
        "            preprocessed = self.preprocessing(image=img, mask=mask)\n",
        "            img = preprocessed['image']\n",
        "            mask = preprocessed['mask']\n",
        "        return img, mask\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_ids)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PWZg9HaYFvhw",
        "colab_type": "text"
      },
      "source": [
        "From the \\_\\_getitem\\_\\_() method we can tell that the 'y' in the training data actually is the mask, which has a shape of (W, L, 4). The value of the mask is binary. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "56Ya9bUAKjun",
        "colab_type": "text"
      },
      "source": [
        "# Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQfkzO6Xpvu0",
        "colab_type": "code",
        "outputId": "9526a742-bf43-4c8a-81fc-d221fe7085d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "train, sub = get_data(path)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading the training csv...\n",
            "Index(['Image_Label', 'EncodedPixels'], dtype='object')\n",
            "(22184, 2)\n",
            "Reading the training images...\n",
            "There are 5546 images in the original train dataset\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h8MGjXL8Lhhs",
        "colab_type": "code",
        "outputId": "3d673984-c028-4aa4-baab-96042d4141e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        }
      },
      "source": [
        "print(train.shape)\n",
        "train.head()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(22184, 4)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Image_Label</th>\n",
              "      <th>EncodedPixels</th>\n",
              "      <th>label</th>\n",
              "      <th>im_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0011165.jpg_Fish</td>\n",
              "      <td>264918 937 266318 937 267718 937 269118 937 27...</td>\n",
              "      <td>Fish</td>\n",
              "      <td>0011165.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0011165.jpg_Flower</td>\n",
              "      <td>1355565 1002 1356965 1002 1358365 1002 1359765...</td>\n",
              "      <td>Flower</td>\n",
              "      <td>0011165.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0011165.jpg_Gravel</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Gravel</td>\n",
              "      <td>0011165.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0011165.jpg_Sugar</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Sugar</td>\n",
              "      <td>0011165.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>002be4f.jpg_Fish</td>\n",
              "      <td>233813 878 235213 878 236613 878 238010 881 23...</td>\n",
              "      <td>Fish</td>\n",
              "      <td>002be4f.jpg</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          Image_Label  ...        im_id\n",
              "0    0011165.jpg_Fish  ...  0011165.jpg\n",
              "1  0011165.jpg_Flower  ...  0011165.jpg\n",
              "2  0011165.jpg_Gravel  ...  0011165.jpg\n",
              "3   0011165.jpg_Sugar  ...  0011165.jpg\n",
              "4    002be4f.jpg_Fish  ...  002be4f.jpg\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nyZ7_7zoqXST",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "display_images_with_masks(path, train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SKDmxazevrkS",
        "colab_type": "code",
        "outputId": "c7fa1c6b-f103-4473-c31d-32987246c27f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "train_ids, valid_ids, test_ids = split_data(train, sub)\n",
        "\n",
        "print('The size of training sample:', train_ids.shape)\n",
        "print('The size of validation sample:', valid_ids.shape)\n",
        "print('The size of testing sample:', test_ids.shape)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The size of training sample: (4991,)\n",
            "The size of validation sample: (555,)\n",
            "The size of testing sample: (3698,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "76uu3wAFBCpw",
        "colab_type": "text"
      },
      "source": [
        "# Build the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VJYPOUyw3IpZ",
        "colab_type": "code",
        "outputId": "80cf2678-c8e4-4e10-ebb1-bc2cd69a86ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "source": [
        "DEVICE = 'cuda'\n",
        "\n",
        "# ENCODER = 'resnet50'\n",
        "ENCODER = 'inceptionresnetv2'\n",
        "ENCODER_WEIGHTS = 'imagenet'\n",
        "ACTIVATION = None\n",
        "model = smp.Unet(\n",
        "    encoder_name=ENCODER, \n",
        "    encoder_weights=ENCODER_WEIGHTS, \n",
        "    classes=4, \n",
        "    activation=ACTIVATION,\n",
        ")\n",
        "preprocessing_fn = smp.encoders.get_preprocessing_fn(ENCODER, ENCODER_WEIGHTS)\n",
        "\n",
        "num_workers = 0\n",
        "bs = 16\n",
        "train_dataset = CloudDataset(df=train, datatype='train', img_ids=train_ids, \n",
        "                             transforms = get_training_augmentation(), \n",
        "                             preprocessing=get_preprocessing(preprocessing_fn))\n",
        "\n",
        "valid_dataset = CloudDataset(df=train, datatype='valid', img_ids=valid_ids, \n",
        "                             transforms = get_validation_augmentation(), \n",
        "                             preprocessing=get_preprocessing(preprocessing_fn))\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=bs, shuffle=True, \n",
        "                          num_workers=num_workers)\n",
        "valid_loader = DataLoader(valid_dataset, batch_size=bs, shuffle=False, \n",
        "                          num_workers=num_workers)\n",
        "\n",
        "loaders = {\n",
        "    \"train\": train_loader,\n",
        "    \"valid\": valid_loader\n",
        "}"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"http://data.lip6.fr/cadene/pretrainedmodels/inceptionresnetv2-520b38e4.pth\" to /root/.cache/torch/checkpoints/inceptionresnetv2-520b38e4.pth\n",
            "100%|██████████| 213M/213M [10:39<00:00, 350kB/s]\n",
            "/usr/local/lib/python3.6/dist-packages/albumentations/augmentations/transforms.py:2247: UserWarning:\n",
            "\n",
            "Using lambda is incompatible with multiprocessing. Consider using regular functions or partial().\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eQ0BQc0kUMIl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "outputId": "0ddda8a1-38e9-4c63-8b7b-7d01d556e779"
      },
      "source": [
        "num_epochs = 19\n",
        "logdir = '/content/gdrive/My Drive/kaggle_cloud/log_inceptionresnetv2'\n",
        "\n",
        "# model, criterion, optimizer\n",
        "optimizer = torch.optim.Adam([\n",
        "    {'params': model.decoder.parameters(), 'lr': 1e-2}, \n",
        "    {'params': model.encoder.parameters(), 'lr': 1e-3},  \n",
        "])\n",
        "\n",
        "opt_level = 'O1'\n",
        "model.cuda()\n",
        "model, optimizer = amp.initialize(model, optimizer, opt_level=opt_level)\n",
        "\n",
        "scheduler = ReduceLROnPlateau(optimizer, factor=0.15, patience=2)\n",
        "criterion = smp.utils.losses.BCEDiceLoss(eps=1.)\n",
        "runner = SupervisedRunner()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.\n",
            "\n",
            "Defaults for this optimization level are:\n",
            "enabled                : True\n",
            "opt_level              : O1\n",
            "cast_model_type        : None\n",
            "patch_torch_functions  : True\n",
            "keep_batchnorm_fp32    : None\n",
            "master_weights         : None\n",
            "loss_scale             : dynamic\n",
            "Processing user overrides (additional kwargs that are not None)...\n",
            "After processing overrides, optimization options are:\n",
            "enabled                : True\n",
            "opt_level              : O1\n",
            "cast_model_type        : None\n",
            "patch_torch_functions  : True\n",
            "keep_batchnorm_fp32    : None\n",
            "master_weights         : None\n",
            "loss_scale             : dynamic\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SbESLniG9ov7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d4b2f3a0-d81b-4bda-887d-7bb9162b0965"
      },
      "source": [
        "runner.train(\n",
        "    model=model,\n",
        "    criterion=criterion,\n",
        "    optimizer=optimizer,\n",
        "    scheduler=scheduler,\n",
        "    loaders=loaders,\n",
        "    callbacks=[DiceCallback(), EarlyStoppingCallback(patience=5, min_delta=0.001)],\n",
        "    logdir=logdir,\n",
        "    num_epochs=num_epochs,\n",
        "    verbose=True\n",
        ")"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1/19 * Epoch (train): 100% 312/312 [50:50<00:00, 10.11s/it, dice=0.456, loss=0.841]\n",
            "1/19 * Epoch (valid): 100% 35/35 [04:04<00:00,  6.43s/it, dice=0.374, loss=1.068]\n",
            "[2019-11-11 01:25:46,588] \n",
            "1/19 * Epoch 1 (train): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=1.8385 | _timers/batch_time=8.7384 | _timers/data_time=8.6485 | _timers/model_time=0.0898 | dice=0.3961 | loss=0.9596\n",
            "1/19 * Epoch 1 (valid): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=2.3953 | _timers/batch_time=6.7466 | _timers/data_time=6.6974 | _timers/model_time=0.0491 | dice=0.4150 | loss=1.0052\n",
            "2/19 * Epoch (train): 100% 312/312 [24:25<00:00,  4.62s/it, dice=0.386, loss=0.950]\n",
            "2/19 * Epoch (valid): 100% 35/35 [01:08<00:00,  1.79s/it, dice=0.492, loss=0.854]\n",
            "[2019-11-11 01:51:37,273] \n",
            "2/19 * Epoch 2 (train): _base/lr=0.0100 | _base/momentum=0.9000 | _timers/_fps=4.4030 | _timers/batch_time=3.6571 | _timers/data_time=3.5686 | _timers/model_time=0.0884 | dice=0.4514 | loss=0.8804\n",
            "2/19 * Epoch 2 (valid): _base/lr=0.0100 | _base/momentum=0.9000 | _timers/_fps=9.3638 | _timers/batch_time=1.7173 | _timers/data_time=1.6675 | _timers/model_time=0.0498 | dice=0.4651 | loss=0.9440\n",
            "3/19 * Epoch (train): 100% 312/312 [24:30<00:00,  4.56s/it, dice=0.468, loss=0.799]\n",
            "3/19 * Epoch (valid): 100% 35/35 [01:07<00:00,  1.74s/it, dice=0.494, loss=0.816]\n",
            "[2019-11-11 02:17:31,754] \n",
            "3/19 * Epoch 3 (train): _base/lr=0.0100 | _base/momentum=0.9000 | _timers/_fps=4.3843 | _timers/batch_time=3.6743 | _timers/data_time=3.5859 | _timers/model_time=0.0884 | dice=0.4694 | loss=0.8555\n",
            "3/19 * Epoch 3 (valid): _base/lr=0.0100 | _base/momentum=0.9000 | _timers/_fps=9.6105 | _timers/batch_time=1.6724 | _timers/data_time=1.6233 | _timers/model_time=0.0490 | dice=0.4916 | loss=0.8390\n",
            "4/19 * Epoch (train): 100% 312/312 [24:29<00:00,  4.49s/it, dice=0.517, loss=0.798]\n",
            "4/19 * Epoch (valid): 100% 35/35 [01:08<00:00,  1.79s/it, dice=0.531, loss=0.794]\n",
            "[2019-11-11 02:43:19,435] \n",
            "4/19 * Epoch 4 (train): _base/lr=0.0100 | _base/momentum=0.9000 | _timers/_fps=4.3887 | _timers/batch_time=3.6696 | _timers/data_time=3.5810 | _timers/model_time=0.0884 | dice=0.4786 | loss=0.8413\n",
            "4/19 * Epoch 4 (valid): _base/lr=0.0100 | _base/momentum=0.9000 | _timers/_fps=9.4285 | _timers/batch_time=1.7048 | _timers/data_time=1.6551 | _timers/model_time=0.0496 | dice=0.4797 | loss=0.9245\n",
            "5/19 * Epoch (train): 100% 312/312 [24:54<00:00,  4.69s/it, dice=0.415, loss=0.919]\n",
            "5/19 * Epoch (valid): 100% 35/35 [01:08<00:00,  1.79s/it, dice=0.484, loss=0.847]\n",
            "[2019-11-11 03:09:33,890] \n",
            "5/19 * Epoch 5 (train): _base/lr=0.0100 | _base/momentum=0.9000 | _timers/_fps=4.2885 | _timers/batch_time=3.7522 | _timers/data_time=3.6632 | _timers/model_time=0.0889 | dice=0.4871 | loss=0.8260\n",
            "5/19 * Epoch 5 (valid): _base/lr=0.0100 | _base/momentum=0.9000 | _timers/_fps=9.3740 | _timers/batch_time=1.7150 | _timers/data_time=1.6653 | _timers/model_time=0.0496 | dice=0.5026 | loss=0.8447\n",
            "6/19 * Epoch (train): 100% 312/312 [24:50<00:00,  4.67s/it, dice=0.509, loss=0.833]\n",
            "6/19 * Epoch (valid): 100% 35/35 [01:10<00:00,  1.89s/it, dice=0.505, loss=0.795]\n",
            "[2019-11-11 03:35:46,780] \n",
            "6/19 * Epoch 6 (train): _base/lr=0.0100 | _base/momentum=0.9000 | _timers/_fps=4.3117 | _timers/batch_time=3.7382 | _timers/data_time=3.6497 | _timers/model_time=0.0883 | dice=0.4923 | loss=0.8186\n",
            "6/19 * Epoch 6 (valid): _base/lr=0.0100 | _base/momentum=0.9000 | _timers/_fps=9.0326 | _timers/batch_time=1.7794 | _timers/data_time=1.7285 | _timers/model_time=0.0508 | dice=0.4979 | loss=0.8451\n",
            "7/19 * Epoch (train): 100% 312/312 [25:40<00:00,  4.96s/it, dice=0.500, loss=0.805]\n",
            "7/19 * Epoch (valid): 100% 35/35 [01:11<00:00,  1.87s/it, dice=0.519, loss=0.783]\n",
            "[2019-11-11 04:02:55,471] \n",
            "7/19 * Epoch 7 (train): _base/lr=0.0015 | _base/momentum=0.9000 | _timers/_fps=4.1328 | _timers/batch_time=3.8941 | _timers/data_time=3.8054 | _timers/model_time=0.0885 | dice=0.5108 | loss=0.7871\n",
            "7/19 * Epoch 7 (valid): _base/lr=0.0015 | _base/momentum=0.9000 | _timers/_fps=8.9298 | _timers/batch_time=1.7994 | _timers/data_time=1.7491 | _timers/model_time=0.0502 | dice=0.5411 | loss=0.7621\n",
            "8/19 * Epoch (train): 100% 312/312 [25:34<00:00,  4.80s/it, dice=0.525, loss=0.726]\n",
            "8/19 * Epoch (valid): 100% 35/35 [01:11<00:00,  1.84s/it, dice=0.537, loss=0.748]\n",
            "[2019-11-11 04:29:52,073] \n",
            "8/19 * Epoch 8 (train): _base/lr=0.0015 | _base/momentum=0.9000 | _timers/_fps=4.1507 | _timers/batch_time=3.8776 | _timers/data_time=3.7890 | _timers/model_time=0.0885 | dice=0.5165 | loss=0.7777\n",
            "8/19 * Epoch 8 (valid): _base/lr=0.0015 | _base/momentum=0.9000 | _timers/_fps=8.9926 | _timers/batch_time=1.7872 | _timers/data_time=1.7365 | _timers/model_time=0.0506 | dice=0.5375 | loss=0.7655\n",
            "9/19 * Epoch (train): 100% 312/312 [25:14<00:00,  4.69s/it, dice=0.527, loss=0.706]\n",
            "9/19 * Epoch (valid): 100% 35/35 [01:10<00:00,  1.81s/it, dice=0.533, loss=0.768]\n",
            "[2019-11-11 04:56:33,334] \n",
            "9/19 * Epoch 9 (train): _base/lr=0.0015 | _base/momentum=0.9000 | _timers/_fps=4.2196 | _timers/batch_time=3.8144 | _timers/data_time=3.7251 | _timers/model_time=0.0891 | dice=0.5226 | loss=0.7667\n",
            "9/19 * Epoch 9 (valid): _base/lr=0.0015 | _base/momentum=0.9000 | _timers/_fps=9.1328 | _timers/batch_time=1.7600 | _timers/data_time=1.7086 | _timers/model_time=0.0513 | dice=0.5465 | loss=0.7611\n",
            "10/19 * Epoch (train): 100% 312/312 [25:39<00:00,  4.88s/it, dice=0.560, loss=0.702]\n",
            "10/19 * Epoch (valid): 100% 35/35 [01:10<00:00,  1.83s/it, dice=0.529, loss=0.761]\n",
            "[2019-11-11 05:23:40,319] \n",
            "10/19 * Epoch 10 (train): _base/lr=0.0015 | _base/momentum=0.9000 | _timers/_fps=4.1346 | _timers/batch_time=3.8940 | _timers/data_time=3.8054 | _timers/model_time=0.0885 | dice=0.5198 | loss=0.7753\n",
            "10/19 * Epoch 10 (valid): _base/lr=0.0015 | _base/momentum=0.9000 | _timers/_fps=9.0231 | _timers/batch_time=1.7823 | _timers/data_time=1.7323 | _timers/model_time=0.0499 | dice=0.5447 | loss=0.7523\n",
            "11/19 * Epoch (train): 100% 312/312 [25:23<00:00,  4.61s/it, dice=0.552, loss=0.740]\n",
            "11/19 * Epoch (valid): 100% 35/35 [01:11<00:00,  1.85s/it, dice=0.528, loss=0.774]\n",
            "[2019-11-11 05:50:26,517] \n",
            "11/19 * Epoch 11 (train): _base/lr=0.0015 | _base/momentum=0.9000 | _timers/_fps=4.1911 | _timers/batch_time=3.8420 | _timers/data_time=3.7527 | _timers/model_time=0.0892 | dice=0.5271 | loss=0.7638\n",
            "11/19 * Epoch 11 (valid): _base/lr=0.0015 | _base/momentum=0.9000 | _timers/_fps=8.9352 | _timers/batch_time=1.7995 | _timers/data_time=1.7492 | _timers/model_time=0.0502 | dice=0.5455 | loss=0.7613\n",
            "12/19 * Epoch (train): 100% 312/312 [25:22<00:00,  4.63s/it, dice=0.497, loss=0.907]\n",
            "12/19 * Epoch (valid): 100% 35/35 [01:09<00:00,  1.81s/it, dice=0.511, loss=0.782]\n",
            "[2019-11-11 06:17:10,131] \n",
            "12/19 * Epoch 12 (train): _base/lr=0.0015 | _base/momentum=0.9000 | _timers/_fps=4.1890 | _timers/batch_time=3.8397 | _timers/data_time=3.7510 | _timers/model_time=0.0885 | dice=0.5295 | loss=0.7597\n",
            "12/19 * Epoch 12 (valid): _base/lr=0.0015 | _base/momentum=0.9000 | _timers/_fps=9.1988 | _timers/batch_time=1.7474 | _timers/data_time=1.6979 | _timers/model_time=0.0494 | dice=0.5372 | loss=0.7601\n",
            "13/19 * Epoch (train): 100% 312/312 [25:17<00:00,  4.77s/it, dice=0.507, loss=0.906]\n",
            "13/19 * Epoch (valid): 100% 35/35 [01:10<00:00,  1.83s/it, dice=0.529, loss=0.764]\n",
            "[2019-11-11 06:43:47,936] \n",
            "13/19 * Epoch 13 (train): _base/lr=0.0015 | _base/momentum=0.9000 | _timers/_fps=4.2085 | _timers/batch_time=3.8215 | _timers/data_time=3.7329 | _timers/model_time=0.0885 | dice=0.5288 | loss=0.7599\n",
            "13/19 * Epoch 13 (valid): _base/lr=0.0015 | _base/momentum=0.9000 | _timers/_fps=9.1425 | _timers/batch_time=1.7575 | _timers/data_time=1.7077 | _timers/model_time=0.0497 | dice=0.5445 | loss=0.7528\n",
            "14/19 * Epoch (train): 100% 312/312 [25:34<00:00,  4.72s/it, dice=0.537, loss=0.685]\n",
            "14/19 * Epoch (valid): 100% 35/35 [01:11<00:00,  1.86s/it, dice=0.534, loss=0.756]\n",
            "[2019-11-11 07:10:51,512] \n",
            "14/19 * Epoch 14 (train): _base/lr=0.0002 | _base/momentum=0.9000 | _timers/_fps=4.1496 | _timers/batch_time=3.8775 | _timers/data_time=3.7888 | _timers/model_time=0.0886 | dice=0.5386 | loss=0.7422\n",
            "14/19 * Epoch 14 (valid): _base/lr=0.0002 | _base/momentum=0.9000 | _timers/_fps=8.8798 | _timers/batch_time=1.8092 | _timers/data_time=1.7578 | _timers/model_time=0.0513 | dice=0.5492 | loss=0.7453\n",
            "15/19 * Epoch (train): 100% 312/312 [25:39<00:00,  4.62s/it, dice=0.568, loss=0.687]\n",
            "15/19 * Epoch (valid): 100% 35/35 [01:11<00:00,  1.87s/it, dice=0.531, loss=0.764]\n",
            "[2019-11-11 07:37:53,552] \n",
            "15/19 * Epoch 15 (train): _base/lr=0.0002 | _base/momentum=0.9000 | _timers/_fps=4.1349 | _timers/batch_time=3.8932 | _timers/data_time=3.8039 | _timers/model_time=0.0891 | dice=0.5391 | loss=0.7414\n",
            "15/19 * Epoch 15 (valid): _base/lr=0.0002 | _base/momentum=0.9000 | _timers/_fps=8.9216 | _timers/batch_time=1.8022 | _timers/data_time=1.7518 | _timers/model_time=0.0504 | dice=0.5518 | loss=0.7454\n",
            "16/19 * Epoch (train): 100% 312/312 [25:36<00:00,  4.90s/it, dice=0.553, loss=0.718]\n",
            "16/19 * Epoch (valid): 100% 35/35 [01:11<00:00,  1.85s/it, dice=0.535, loss=0.754]\n",
            "[2019-11-11 08:04:52,753] \n",
            "16/19 * Epoch 16 (train): _base/lr=0.0002 | _base/momentum=0.9000 | _timers/_fps=4.1446 | _timers/batch_time=3.8832 | _timers/data_time=3.7945 | _timers/model_time=0.0886 | dice=0.5373 | loss=0.7442\n",
            "16/19 * Epoch 16 (valid): _base/lr=0.0002 | _base/momentum=0.9000 | _timers/_fps=8.9952 | _timers/batch_time=1.7874 | _timers/data_time=1.7366 | _timers/model_time=0.0507 | dice=0.5504 | loss=0.7454\n",
            "17/19 * Epoch (train): 100% 312/312 [25:33<00:00,  4.81s/it, dice=0.498, loss=0.854]\n",
            "17/19 * Epoch (valid): 100% 35/35 [01:11<00:00,  1.83s/it, dice=0.531, loss=0.765]\n",
            "[2019-11-11 08:31:48,129] \n",
            "17/19 * Epoch 17 (train): _base/lr=0.0002 | _base/momentum=0.9000 | _timers/_fps=4.1557 | _timers/batch_time=3.8746 | _timers/data_time=3.7853 | _timers/model_time=0.0892 | dice=0.5387 | loss=0.7429\n",
            "17/19 * Epoch 17 (valid): _base/lr=0.0002 | _base/momentum=0.9000 | _timers/_fps=9.0076 | _timers/batch_time=1.7868 | _timers/data_time=1.7363 | _timers/model_time=0.0504 | dice=0.5503 | loss=0.7479\n",
            "18/19 * Epoch (train): 100% 312/312 [25:22<00:00,  4.64s/it, dice=0.539, loss=0.734]\n",
            "18/19 * Epoch (valid): 100% 35/35 [01:10<00:00,  1.84s/it, dice=0.535, loss=0.751]\n",
            "[2019-11-11 08:58:32,150] \n",
            "18/19 * Epoch 18 (train): _base/lr=3.375e-05 | _base/momentum=0.9000 | _timers/_fps=4.1943 | _timers/batch_time=3.8398 | _timers/data_time=3.7512 | _timers/model_time=0.0885 | dice=0.5416 | loss=0.7380\n",
            "18/19 * Epoch 18 (valid): _base/lr=3.375e-05 | _base/momentum=0.9000 | _timers/_fps=9.0802 | _timers/batch_time=1.7707 | _timers/data_time=1.7202 | _timers/model_time=0.0505 | dice=0.5495 | loss=0.7465\n",
            "19/19 * Epoch (train): 100% 312/312 [25:23<00:00,  4.75s/it, dice=0.563, loss=0.680]\n",
            "19/19 * Epoch (valid): 100% 35/35 [01:10<00:00,  1.84s/it, dice=0.526, loss=0.765]\n",
            "Early stop at 18 epoch\n",
            "[2019-11-11 09:25:17,130] \n",
            "19/19 * Epoch 19 (train): _base/lr=3.375e-05 | _base/momentum=0.9000 | _timers/_fps=4.1902 | _timers/batch_time=3.8425 | _timers/data_time=3.7539 | _timers/model_time=0.0885 | dice=0.5384 | loss=0.7417\n",
            "19/19 * Epoch 19 (valid): _base/lr=3.375e-05 | _base/momentum=0.9000 | _timers/_fps=9.0479 | _timers/batch_time=1.7764 | _timers/data_time=1.7264 | _timers/model_time=0.0500 | dice=0.5470 | loss=0.7473\n",
            "Top best models:\n",
            "/content/gdrive/My Drive/kaggle_cloud/log_inceptionresnetv2/checkpoints/train.14.pth\t0.7453\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jk4m76X-s8Ga",
        "colab_type": "text"
      },
      "source": [
        "# Visualize the Model Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A0Bs4az9OeO1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json\n",
        "metric_file = '/content/gdrive/My Drive/kaggle_cloud/run_log1109/checkpoints/_metrics.json'\n",
        "\n",
        "with open(metric_file, 'r') as f:\n",
        "  metrics = json.load(f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MhTvL6y2PW7J",
        "colab_type": "code",
        "outputId": "d3be45a8-67c5-4bd3-9c64-b8750fe7b91f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        }
      },
      "source": [
        "print(metrics.keys())\n",
        "metrics['epoch_6']"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dict_keys(['best', 'last', 'train.19', 'epoch_0', 'epoch_1', 'epoch_2', 'epoch_3', 'epoch_4', 'epoch_5', 'epoch_6', 'epoch_7', 'epoch_8', 'epoch_9', 'epoch_10', 'epoch_11', 'epoch_12', 'epoch_13', 'epoch_14', 'epoch_15', 'epoch_16', 'epoch_17', 'epoch_18'])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/gdrive/My Drive/kaggle_cloud/run_log1109/checkpoints/train.7.pth',\n",
              " 0.8074309161731174,\n",
              " {'_base/lr': 0.01,\n",
              "  '_base/momentum': 0.9,\n",
              "  '_timers/_fps': 9.615288928372232,\n",
              "  '_timers/batch_time': 1.6704837254115512,\n",
              "  '_timers/data_time': 1.6501800673348563,\n",
              "  '_timers/model_time': 0.020228951317923415,\n",
              "  'dice': 0.5196731337479185,\n",
              "  'loss': 0.8074309161731174}]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vUyJ0yoptRgq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_metrics_json(metric_file, metric_name, n_epochs, do_save_fig=False, figname=None):\n",
        "  \"\"\"\n",
        "  Plot the change of a metric in the training process saved in a *.json file.\n",
        "\n",
        "  metric_name: str. \n",
        "    The name of the metric variable. Choose from: '_base/lr', 'dice', 'loss'. \n",
        "  \"\"\"\n",
        "\n",
        "  with open(metric_file, 'r') as fm: \n",
        "    metrics = json.load(fm)\n",
        "\n",
        "    metric_hist = []\n",
        "    for i in range(n_epochs):\n",
        "      metric_i = metrics['epoch_{}'.format(i)][2][metric_name]\n",
        "      metric_hist.append(metric_i)\n",
        "\n",
        "  plt.plot(range(n_epochs), metric_hist)\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.ylabel(metric_name)\n",
        "\n",
        "  if do_save_fig:\n",
        "    if not figname:\n",
        "      figname = metric_file.replace('_metrics.json', metric_name + '.png')\n",
        "      print(figname)\n",
        "    plt.savefig(figname)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K4Cf57CGwZ2k",
        "colab_type": "code",
        "outputId": "5072a294-8d1e-4785-c45d-e8a38307faa9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        }
      },
      "source": [
        "plot_metrics_json(metric_file, metric_name='loss', n_epochs=18, do_save_fig=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/kaggle_cloud/run_log1109/checkpoints/loss.png\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAEGCAYAAACZ0MnKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3dd3Sc5ZX48e+dUR11aeQiaeQiycYF\nXDCuItRgU4KBTcGEAAkbfimQAmRDkoVl2eQk2XQSkkASEkpoS0JJsHEILWDc5SLbuMpWs2TLVrXV\npef3x7wSg6wykqZq7uccHc28ba7HI129z32KGGNQSimlvGELdgBKKaXChyYNpZRSXtOkoZRSymua\nNJRSSnlNk4ZSSimvRQU7AF9xOp1m8uTJwQ5DKaXCytatW08YYzK9PX7MJI3JkyezZcuWYIehlFJh\nRURKh3O8Nk8ppZTymiYNpZRSXtOkoZRSymuaNJRSSnlNk4ZSSimvadJQSinlNU0aSimlvKZJQwVE\n2clm3th7LNhhKKVGSZOGCoifvraPLz5ZRHe3rt+iVDjTpKECYmtZHW2d3Rxvagt2KEqpUdCkofzu\neFMr5bUtAJTXNQc5GqXUaGjSUH5XVFrf+7jspCYNpcKZJg3ld9vK6oi2CyJ6p6FUuBszs9yq0FVU\nVsesrBSONX7QTKWUCk96p6H8qr2zm50VDczPTcOV5qC8Vu80lApnmjSUX+2paqSts5tzJ6WRkx6v\nzVNKhTlNGsqvikrrAJg/KZXcdAfVja20dXYFOSql1Ehp0lB+VVRWx8SUOCamxONKc2AMHK1vDXZY\nSqkRivik0dVteHpTGSdO6aAzf9hWVs/83DQAXOkOAMq0rqFU2Ir4pFFW28y9L+7iB2v2BjuUMae6\noZXK+hbmT3InjVwraWgxXKnwFfFJY4ozgX8/fyrPb61g85HaYIczphSVWfWM3FQAxiXFEhNl02K4\nUmEs4pMGwFcuyScrJY57X9xFZ1d3sMMZM4pK64iJsjErKwUAm03ISY3XOw2lwpgmDcARE8V9H5vF\n3uom/vTekWCHM2YUldVxdnYKMVEffMxc6Q4d4KdUGPNr0hCRFSKyT0QOisg9/eyfJCKvi8hOEXlL\nRHI89nWJyHbr62V/xgmwfNZ4Lpyeyc9e2091g/buGa22zi52VTb2Nk31cOlYDaXCmt+ShojYgYeA\ny4GZwCoRmdnnsB8DjxtjzgEeAL7vsa/FGDPX+rraX3F6xMt/Xz2Ljm7Dd1/Z4++XG/N2H22kvcs9\nqM+TK81BfXMHja0dQYpMKTUa/rzTWAgcNMaUGGPagWeAlX2OmQm8YT1+s5/9ATUpI4EvXZjH33dW\n8e6BE8EMJez1DurL/XDS0B5USoU3fyaNbKDc43mFtc3TDuA66/G1QJKIZFjP40Rki4hsEJFr+nsB\nEbnNOmZLTU2NT4L+wgV5TMpwcN9Lu3Tk8igUldWRnRrPuOS4D2139SYNrWsoFY6CXQi/G7hARLYB\nFwCVQM9v6knGmAXADcDPRSSv78nGmEeMMQuMMQsyMzN9ElBctJ37r55FyYnT/P6dwz65ZiQqKq3v\nHZ/hyZWmdxpKhTN/Jo1KwOXxPMfa1ssYc9QYc50xZh7wHWtbvfW90vpeArwFzPNjrB9y0fRxrJg1\ngV++cUB/uY3A0foWqhtbObdPERwgxRFNclyUFsOVClP+TBqbgQIRmSIiMcD1wId6QYmIU0R6YvgW\n8Ki1PU1EYnuOAZYBAa1O3/exmdhE+O+/aVF8uLb2TlJ45p0G9HS71aShVDjyW9IwxnQCtwNrgfeB\n54wxu0XkARHp6Q11IbBPRPYD44HvWdtnAFtEZAfuAvkPjDEB/e2dlRrPVy4p4J/vH+Ofe44F8qXD\nXlFZHXHRNmZMTO53vyvNofNPKRWm/LpynzFmNbC6z7b7PB4/Dzzfz3nvAWf7MzZvfG7ZFJ7fWsH9\nf9vNsnwn8TH2YIcUForK6jknO5Voe/9/k+RmOHhz33GMMYhIgKNTSo1GsAvhIS0mysb/rJxNRV0L\nv37rYLDDCQutHV3sOdowYNMUgCstnrbObmqadGZhpcKNJo0hLMnL4Jq5WTz8dgklNaeCHU7I21XZ\nQEeXOWMkuKccnSJdqbClScML375yBrFRNv7r5d0YY4IdTkgbqggOHgP8tAeVUmFHk4YXxiXFcddl\n03jnwAlWF1cHO5yQVlRWR266A2di7IDHZKfGAzrAT6lwpEnDSzcunsTMick88PfdnGrrDHY4IckY\nQ1FZ/aBNU+AeQDk+OVabp5QKQ5o0vBRlt/Hda2dzrLGNX/xzf7DDCUkVdS3UNLWdMUlhf3J1rIZS\nYUmTxjDMz03j+vNcPLruCHurG4MdTsjpWalvXu7QScOV5qCiTpunlAo3mjSG6ZsrziI5Lop7X9yl\nRfE+ikrrcMTYOWtC0pDH5qQ7ONrQQnunrpSoVDjRpDFMaQkxfHPFWWw+UsdfiiqHPiGCFJXVc05O\nClEDDOrz5EqLxxj3PFVKqfChSWMEPrnAxbzcVL6/+n0amnUxIYCW9i7er2r0qp4B2u1WqXClSWME\nbDbhu9fMpq65nR//Y1+ww+lXdUMrG0pOBuz1dlbU09ltzlh0aSAuHeCnVFjy69xTY9msrBRuWjKZ\nx9Yf4RMLcjgnZ/BupoFwvLGV1cVVvFJcxeYj7qL0X764hHMnpfv9tbcOowgOMD45jmi76FgNpcKM\n3mmMwp2XTSMjIZZ7X9xFV3dwiuI1TW08sf4In3p4PYu+/zr3/20PTa2dfP3SaSTE2HlqY/mQ1/CF\notJ6pjgTSE+I8ep4u03ISXNo85RSYUbvNEYhOS6a/7xyBl97djtPbyrjxsWTAvK6J0+18erual7Z\nWcWGkpN0G8gfl8hXLyngyrMnUjDe3XvpWFMrf9lawX1XzSTFEe23eIwxbCur48Lp44Z1Xk5avI7V\nUCrMaNIYpZVzs3hmcxk/WruPy2dPIGOQ6TNGo+50O2t3V/NKcRXvHTpJV7dhqjOB2y/K58pzspg2\nPvGMacZvWJjLUxvLeHF7JTcvneyXuMBdlzh5up35k4bXROdKd7CruMpPUSml/EGTxiiJCP+zcjaX\n/+IdfrBmLz/6xByfXbuhuYO1e9x3FOsOnqCz2zApw8EXLpjKlWdnMWNi0qDrUczOTuHs7BSe3lTG\nTUsm+W3tip5Bfd4WwXvkpjuoa+6gqbWDpDj/3QkppXxHk4YPFIxP4tbzp/Dw2yVsPlJLXLSd2Cgb\nsVF2YqNtHzyOslnP7R98j7L2R3/wuKW9i3/sOcY7B2ro6DLkpMXz7+dP5apzJjIrK3lYv/xXLczl\n2y8Us628fti/1L21tbSOxNgopo0felCfJ1ea1e22toWZWZo0lAoHmjR85KuXFADurq6tHV20dXbT\n1tHN6bZOak93u593dtHa0U1bz/5BRkNnp8bz2WVTuPLsiZyTkzLiu4Sr52bx3Vf28PTGMr8ljaLS\neua4UrDbhhejK92a7baumZlZ/S8Nq5QKLZo0fMQRE8W3Lp8xrHOMMbR3uZNHa0cXbR0fJJK8zASf\nNCclxkaxcm4WL2yr5N6PzSTZx81Ap9s62VvdyO0X5Q/73N4BfloMVypsaJfbIBIRYqPsJMdFMy4p\nDle6g/xxieSPO7OoPRqrFubS2tHNS9t8P+3Jjop6ug3M83IkuKeU+GiSYqM0aSgVRjRpRICzs1OY\nlZXMnzeW+XySxaKelfpcw08aIkJOuoNyne1WqbChSSMCiAirFuayt7qJHRUNPr12UVk9eZkJIx4H\nkpuuYzWUCieaNCLEyrlZxEfbeXpjmc+u2TOoz9tJCvvjskaF6zTzSoUHTRoRIikumqvnZPHyjqM0\ntfpmZt7DJ05T19wxql5ZrnQHrR3d1Jxq80lMSin/0qQRQVYtyqWlo4uXth/1yfWKyuoBmD+KO40P\nelBpXUOpcKBJI4LMyUlhxsRknvJRQXxraR1JcVHkZyaO+Bq9YzW0rqFUWNCkEUFEhBsWuthT1Uhx\n5egL4tvK6pjrSsU2zEF9nnLSdKyGUuFEk0aEWTkvm7hoG09vGl1BvKm1g33HmkZVBAeIi7YzLilW\np0hXKkxo0ogwyXHRfOycLF7afpRTbZ0jvs6O8gaMGf4khf1xpTu0pqFUmNCkEYFWLcqlub2Ll0dR\nEC8qq0ME5uaOfsVCV1q8LvuqVJjQpBGB5rlSOWtC0qiaqLaW1lEwLtEnc1nlpjuoamiho2vgCRyV\nUqFBk0YE6hkhXlzZQPEIRoh3d49+UJ+nnHQH3Qaq6lt9cj2llP9o0ohQ18zLJjbKxtObh3+3UXLi\nFI2tnczz0VTrPetqaBOVUqHPr0lDRFaIyD4ROSgi9/Szf5KIvC4iO0XkLRHJ8dh3s4gcsL5u9mec\nkSglPpqrzsnipW2VnB5mQbyo1BrU56OkkZthdbvVHlRKhTy/JQ0RsQMPAZcDM4FVIjKzz2E/Bh43\nxpwDPAB83zo3HfgvYBGwEPgvEfHPCkIR7IZFLk63d/G3HcMriG8trSMlPpqpzgSfxDEhOY5ou+hY\nDaXCgD/vNBYCB40xJcaYduAZYGWfY2YCb1iP3/TYvxx4zRhTa4ypA14DVvgx1og0PzeNaeMTh10Q\nLyqrY37u6Ab1ebLbhKxU7UGlVDjwZ9LIBso9nldY2zztAK6zHl8LJIlIhpfnIiK3icgWEdlSU1Pj\ns8AjRU9BfEdFA7u8HCHe0NLBgeOnfL50bK6uq6FUWAh2Ifxu4AIR2QZcAFQCXd6ebIx5xBizwBiz\nIDMz018xjmnXWgXxZ7wsiG8vH/0khf3JSXNQoXcaSoU8fyaNSsDl8TzH2tbLGHPUGHOdMWYe8B1r\nW7035yrfSHXEcOXZE3lx21Ga24cuiBeV1mETmOMa/aA+T670eE6ebh92UV4pFVj+TBqbgQIRmSIi\nMcD1wMueB4iIU0R6YvgW8Kj1eC1wmYikWQXwy6xtyg9WLcrlVFsnf99RNeSxRWV1TBufRGJslE9j\n6J0iXXtQKRXS/JY0jDGdwO24f9m/DzxnjNktIg+IyNXWYRcC+0RkPzAe+J51bi3wP7gTz2bgAWub\n8oMFk9LIH5fIU0MUxLu7DdvL6n02qM+TK03X1VAqHPj2z8U+jDGrgdV9tt3n8fh54PkBzn2UD+48\nlB/1FMT/5+972HO0kZlZyf0ed+D4KZraOn1eBAf3pIWgA/yUCnXBLoSrEHHdvGxihiiIF5XVAb4v\nggOkOaJJjI3SsRpKhThNGgqAtIQYrpg9gReKKmlp778D29bSOtITYphsjeD2JREhJy2eCq1pKBXS\nNGmoXqsW5tLU1snfd/Y/QrxnUJ+Ibwb19eVKd2jzlFIhTpOG6rVwSjpTMxP6HSFe39xOSc1pn01S\n2J9cazEmX6xfrpTyD00aqpd7DfFcisrq2Vvd+KF928p8O0lhf1xp8bR0dHHydLvfXkMpNTqaNNSH\nXDc/hxi7jWc2lX9oe1FZHXabMMeV4rfX1h5USoU+TRrqQ9ITYlgxewJ/Lar4UEF8a2kdMyYm4Yjx\nXy/t3gF+mjSUClmaNNQZVi3MpbG1k9XF7hHiXd2GHeX1fm2aAvf8UwAVOnGhUiFLk4Y6w+Kp6Uxx\nflAQ31fdxOn2Lr8njfgYO87EWMpO6p2GUqFKk4Y6g3uEuIstpXXsP9b0waA+PycNgNz0eJ1/SqkQ\npklD9evf5ucQbRee3lRGUVkdzsQYXOnxfn9dV7pDk4ZSIUyThupXRmIsy2dN4K9FlWwsqWV+bprf\nBvV5cqU5OFrfSmdXt99fSyk1fJo01IBuWJhLQ0sHlfUtfplvqj+56Q66ug1VDa0BeT2l1PBo0lAD\nWjw1o3eeqUDUMwByrCYw7XarVGjSpKEGZLMJtxZOISMhhnNy/Deoz1PPuhrhMsCvuKJBE5yKKJo0\n1KBuXDyJTd+5lLhoe0Beb2JKHHabhEUx/HRbJzf8bgP3vrQr2KEoFTCaNNSgRAS7zf8F8B5RdhvZ\nqfFhsYLfC9sqaWrrZGNJLW2d/U8nr9RYo0lDhRxXenzIN08ZY3hifSlx0TZaOrooKq0PdkhKBYQm\nDRVyXGmOkF+MaePhWvYda+Iby8/CbhPWHTwR7JCUCghNGirkuNIdnDjVTnN7Z7BDGdDj64+Q6ojm\n04tymetK5R1NGipCaNJQIcfVO9ttaNY1qhtaWbv7GJ9a4CIu2s6yfCfFFfU0NHcEOzSl/E6Thgo5\nrrTQHqvx1MZSuo3hxsWTADi/wEm3gfUlerehxj5NGirk9K6rEYJ1jfbObp7aVM7F08f13hHNdaWS\nEGPnXW2iUhFAk4YKOekJMThi7CHZg2rNripOnGrjpqWTe7dF220smprBuwc0aaixT5OGCjkigivN\nEZI1jcfXlzI5w8H5+c4PbS/Md3LkZHPINqkp5SuaNFRIcqWHXrfbXZUNbC2t4zNLJmPrM+CxsMCd\nRN47pHcbamzTpKFCUs8AP2NMsEPp9cT6UuKj7Xz83Jwz9hWMS2RcUizvaBOVGuO8Shoi8lURSRa3\nP4hIkYhc5u/gVORypTlobu+i9nR7sEMBoL65nRe3V3LNvGxS4qPP2C8iFOY7ee/QSbq7QyfRKeVr\n3t5pfM4Y0whcBqQBnwF+4LeoVMT7oAdVaNQ1/m9LBW2d3dy0ZNKAxxQWOKk93c6eqsYARqZUYHmb\nNHoacK8AnjDG7PbYppTP9XRnDYUeVF3dhic2lLJwcjozJiYPeNwyqziuU4qosczbpLFVRP6BO2ms\nFZEkQNfjVH6TE0ID/N7ef5yy2mZuWjrwXQbA+OQ4po1P1PEaakzzNmncCtwDnGeMaQaigc/6LSoV\n8RJio3AmxoRED6rH15cyLsm9ZvpQluU72XS4ltYOnSpdjU3eJo0lwD5jTL2I3Aj8J9Dgv7CUgpwQ\nGKtx5MRp3tpXww2Lcom2D/3jUpjvpK2zm6LSugBEp1TgeZs0fgM0i8gc4C7gEPD4UCeJyAoR2Sci\nB0Xknn7254rImyKyTUR2isgV1vbJItIiItutr98O49+kxghXuiPoNY0nN5QSZRNuWJjr1fGLpmYQ\nZROd9VaNWd4mjU7j7jC/EviVMeYhIGmwE0TEDjwEXA7MBFaJyMw+h/0n8JwxZh5wPfBrj32HjDFz\nra8veBmnGkNy0+M5Wt9CV5C6sDa3d/LclnJWzJ7AuOQ4r85JjI1iXm6qFsPVmOVt0mgSkW/h7mr7\niojYcNc1BrMQOGiMKTHGtAPP4E46ngzQ0x0lBTjqZTwqArjSHHR2G6oagtNE9dL2ozS2dnKzxzxT\n3ijMz6S4soG6EBljopQveZs0PgW04R6vUQ3kAD8a4pxsoNzjeYW1zdP9wI0iUgGsBu7w2DfFarZ6\nW0TO7+8FROQ2EdkiIltqamq8/KeocBHMbrfGGB5fX8qMicksmJQ2rHMLCzIwBtaXnPRTdEoFj1dJ\nw0oUfwZSROQqoNUYM2RNwwurgD8ZY3KwxoBYdzFVQK7VbHUn8JSInNFB3hjziDFmgTFmQWZmpg/C\nUaGkZ4BfRRCK4VtK63i/qpGblkxCZHhDkubkpJIYG6VTiqgxydtpRD4JbAI+AXwS2CgiHx/itErA\n5fE8x9rm6VbgOQBjzHogDnAaY9qMMSet7VtxF96neROrGjsmpsRht0lQ1tV47L0jJMdFsXJu1rDP\njbLbWDw1Q+saakzytnnqO7jHaNxsjLkJd73i3iHO2QwUiMgUEYnBXeh+uc8xZcAlACIyA3fSqBGR\nTKuQjohMBQqAEi9jVWNElN3GxJS4gDdPHW9s5dVd1XxigQtHTNSIrlGYn0FZbTNlJ4M/ziTc7aps\n4KpfvsNW7cYcErxNGjZjzHGP5yeHOtcY0wncDqwF3sfdS2q3iDwgIldbh90FfF5EdgBPA7dYvbQ+\nAuwUke3A88AXjDG1Xv+r1JiRm+4I+KjwpzaV0dlt+MziwUeAD6awwN1cqqPDR+/PG8vYVdnIZ/6w\nkfWHtE4UbN7+GfWqiKzF/Ysd3IXx1UOdZIxZ3fc4Y8x9Ho/3AMv6Oe8vwF+8jE2NYa40B2/sOz70\ngT7S0dXNUxvLuHB6JpOdCSO+Tl5mAhOS41h38AQ3LPJujIc6U2dXN2t3V3N+gZPqhlZu+eMmHrlp\nARdM0xpmsHhbCP8G8AhwjvX1iDHmm/4MTClwr6tR09RGS3tgpuVYu7ua401tg85m6w0RobDAybpD\nJ4I2zmQs2HS4ltrT7Xx6US7P3LaYqZmJfP6xLby251iwQ4tYXi/CZIz5izHmTuvrBX8GpVSPnm63\ngZqD6vH3SslNd3DBtHGjvlZhvpP65g72HNWp0kfqleIq4qPtXDBtHBmJsTzz+cXMyErmi09u5ZWd\nVcEOLyINmjREpElEGvv5ahIR/UlQfufqXVfD/0nj/apGNh2p5cbFudhto5/5v2eq9HcO6hiikejq\nNqzdXc3FZ40jPsYOQIojmidvXci83FTueLqIvxZVBDnKyDNUMTvJGJPcz1eSMWbghQWU8hFXmjXA\nLwC9kB5fX0pslI1PLnANfbAXMpNiOWtCkna9HaHNR2o5caqdK86e+KHtSXHRPPa5hSyemsFd/7eD\npzaWBSnCyKRrhKuQ5kyMIT7a7vcV/BpaOnhxWyXXzM0m1RHjs+sW5jvZfKROp0ofgdXFVcRF27jo\nrDOL3o6YKB695TwunJbJt18o5o/rDgchwsikSUOFNBHBlR7v9263z2+toKWji8+MsgDe17ICJ+2d\n3Ww+oj3Gh6O727BmVzUXTR834FiZuGg7D39mAStmTeC//7aH37x1KMBRRiZNGirkudL8O0V6d7fh\nifVHOHdSGrOzU3x67UVT0om2C+/qlCLDsrWsjpqmNi7v0zTVV0yUjV/dMI+r52Txw1f38tPX9uMe\n6qX8ZWTDXZUKIFe6g42HazHGDHseKG/860ANR0428/WP+n6mGkdMFPNz03SQ3zC9srOKmCgbF581\ndC+2KLuNn31qLrFRNh58/QBtHV3cc/lZfvmsKL3TUGHAle7gVFsn9c0dfrn+E+tLcSbGcvnswf+q\nHanCfCe7jzZSq1Ole6W72/DqrmounJZJYqx3f9fabcIP/+0cPrN4Eg//q4T7X95Nt46P8QtNGirk\nudLiAf9MkV52spk39h3nhoUuYqL88+NQWODuequ9qLyzrbyO6sbWM3pNDcVmEx5YOYvPnz+Fx9aX\n8u0XinVgpR9o0lAhLzfDf2M1ntxYik2EGxb5tgDu6ezsFJLiojRpeGl1cTUxdhsXzxj+AEsR4dtX\nzOCOi/N5ZnM5dz23nc6ubj9EGbm0pqFCXs9YjXIfr6vR0t7Fs5vLWT5rPBNSvFvOdSSi7DaW5mXw\nzoETfqvLjBXGGNYUV/GRaU6S44ZaHLR/IsJdl00nLtrOj9buo62zm19cP89vd5KRRt9FFfISYqNI\nT4jxefPU33YcpaGlg5uWTPbpdftTmO+ksr6FUp0qfVDby+s52tDqk/rSly/K596rZrJmVzVffHKr\njpXxEU0aKiy40h0+nX/KGMNj648wbXwii6ak++y6A/lgShFtohrMml3VRNuFS2eO98n1bi2cwnev\nmc3re4/z+ce3BGziy7FMk4YKC6403w7wKyqrZ/fRRm5aMjkgzUVTnAlkp8azTsdrDMgYw+riKgrz\nnaTEj6xpqj83Lp7Ejz8xh3UHT/DZP23S4vgoadJQYcGV7qCyvsUnP/DN7Z389LV9JMVGce28bB9E\nNzQRYVl+Bu/pVOkDKq5soKKuZcgBfSPx8XNzuPeqmWwoqWVXZYPPrx9JNGmosJCb7qCjy1Dd2Dqq\n6xyqOcU1D61j/aGT/MflZ5Hg5TgAXygsyKSxtZNi/aXVr9XF1UTZhMt81DTV11XnuNd7X3dI7/ZG\nQ5OGCgsf9KAaeRPV6uIqrv7lu5w41c7jn1s0quVcR2JpXgag4zX609M0tTTf6dMJIz1lJsUyfXwS\n7x3UJWNHQ5OGCguu9JEP8Ovo6ua7f9/Dl/5cxLQJSbzylcLeAXeB5EyMZebEZN45oOtr9LX7aCNl\ntc1cMXuCX19naX4Gm4/Uak+qUdCkocJCVmo8NoGKYSaNY42t3PC7Dfz+3cPcsnQyz962hIkp8X6K\ncmiFBU6KSutpbu8MWgyhaM2uKuw24bJZ/k0ay/KctHV2U1RW59fXGcs0aaiwEG23MTElfljramwo\nOcmVD77LrspGfnH9XO6/elbQB3gty3fS3tXNpsM6VXoPd9NUNUumZpCe4J+mqR6LpqZjt4k2UY2C\nJg0VNlzp8V41TxljePjtQ3z69xtJjo/ipduXsXJuYHpJDWXh5HRi7Data3jYW93E4ROnufxs/95l\ngHvVv3NyUrQYPgqaNFTYyE13DFkIb2zt4P89sZXvr9nL8lnjefn2QqaNTwpQhEOLj7Fz7qQ03tHx\nGr3WFFdhE1ju56apHsvynOysaKCp1T+zJo91mjRU2HClOTje1DZgEfP9qkau/uW7vLH3OPdeNZOH\nbpjv9dTagVRY4GRvdRM1TW3BDiXojDG8UlzFoikZOBNjA/KaS/Mz6Oo2bCzRJsKR0KShwoYr3d3t\ntr/pRP5aVMG1v15Hc3sXT9+2mFsLp4TsxICF1pQi72kTCQeOn+JQzWmuCEDTVI/5uWnERdu0iWqE\nNGmosNHT7dZzttu2zi6+80Ixdz63g7muVP7+lULOm+z/uaRGY3Z2Cinx0boELO4V+kRguZ+72nqK\ni7Zz3uR0rSuNkCYNFTZ67jR61tWoqGvmE79dz583lvH/LpjKk7cuYlyS/6Y49xW7TVial8G6gyci\nfj3rNbuqOG9yesD/35bmOdl/7BTHm0Y3w0Ak0qShwkZmYixx0TbKTjbz1r7jXPXLdzlcc5rf3ngu\n37p8BlH28Pk4FxY4OdrQSsmJ08EOJWgOHm9i/7FTfh/Q159l+e7R+esPadfb4QqfnzIV8USEnDQH\nL26v5LN/2syE5DhevqOQFUH4pTNaPXUNXzaRGGPYUV4fNqOdVxdXA/hlgsKhzMpKIVlXUxwRTRoq\nrExKd3DiVDvXzs3mhS8tY4ozIdghjUhuuoOctHifdb09cuI0t/xxMysfWsd3X9njk2v62+riKhZM\nSmN8cuCbFO02YUleBusOniBBpDYAABTCSURBVIz4JsLh0qShwsp/rDiLRz5zLj/55BziY+zBDmfE\nRITzC5xsOHRyVGtYt3Z08bPX9nPZz//F1tI6zp2UxjObyjkS4s1eJTWn2FvdxBVBuMvoscxaTdHX\nK0KOdZo0VFiZPiGJy2ZNCNnutMOxLN9JU1snO0c4Vfpb+46z/Of/4hevH2D5rAm8ftcF/ObG+UTb\nbfz0tf0+jta31uxyN00Fs2lxaV5PE6HWNYZDk4ZSQbI0z4kIw+56e7S+hS8+uZVb/rgZu034878v\n4per5jE+OY5xSXHcWjiFl3ccZffR0F23Y3VxFfNyU8lKDd7kkXmZCYxPjtXxGsPk16QhIitEZJ+I\nHBSRe/rZnysib4rINhHZKSJXeOz7lnXePhFZ7s84lQqG9IQYZmUl866XxdiOrm4efvsQl/70bd7c\nd5xvLJ/Omq+e37v+eI/bLphKqiOaH63d54+wR6305Gl2H23kyiA2TYG1mmKek/WHTtKtqyl6zW9J\nQ0TswEPA5cBMYJWIzOxz2H8Czxlj5gHXA7+2zp1pPZ8FrAB+bV1PqTGlMD+TbWV1nG4bfKr0jSUn\nufLBd/j+mr0szXPy2tcv4MsX5RMbdeaPRXJcNF+6MI+39tWwoST0ml56ek2FQq+3pflOak+3s7e6\nKdihhA1/3mksBA4aY0qMMe3AM8DKPscYINl6nAIctR6vBJ4xxrQZYw4DB63rKTWmFOY76egyA06V\nXtPUxp3PbudTj2zgdFsXv7tpAb+/eUHvQMeB3LRkMhOS4/jfV/eGXO+gNbuqmJOTQk7a4P+GQOgZ\nr6FTunjPn0kjGyj3eF5hbfN0P3CjiFQAq4E7hnEuInKbiGwRkS01Nboamgo/CyanERNlO6PrbVe3\n4Yn1R7j4J2/xt51Huf2ifP555wV81Mv1s+Oi7Xzt0gKKyur55/vH/RD5yJTXNrOzoiGovaY8TUyJ\nZ6ozQcdrDEOwC+GrgD8ZY3KAK4AnRMTrmIwxjxhjFhhjFmRmZvotSKX8JS7azsI+8yBtL6/nmofW\nce9Lu5mTk8qrX/sIdy+fPuwuxh8/N4epzgR+tHYvXSHSZr9mVxUAl88OjaQB7llvNx2upWMUXZ8j\niT+TRiXg8nieY23zdCvwHIAxZj0QBzi9PFepMWFZvpN9x5o4cKyJ77xQzLW/XsexxlZ+uWoeT9y6\nkLzMxBFdN8pu4+7l09l/7BQvbguNH5/VxdXMzk4mNyP4TVM9luU5Od3exY7y+mCHEhb8mTQ2AwUi\nMkVEYnAXtl/uc0wZcAmAiMzAnTRqrOOuF5FYEZkCFACb/BirUkFzfoG799MVD77DM5vL+dyyKbx+\n1wV8bE7WqMejXD57Amdnp/DT1/bT1hnc6UUq61vYXl4fMk1TPZbkZSCi4zW85bekYYzpBG4H1gLv\n4+4ltVtEHhCRq63D7gI+LyI7gKeBW4zbbtx3IHuAV4EvG2PCY0IdpYZp5sRkpmYmuKd2v6OQe6+a\nSVJctE+uLSL8x4rpVNa38NTGMp9cc6TWFLubpq4IoaYpgFSHu+uzjtfwjl+XNTPGrMZd4Pbcdp/H\n4z3AsgHO/R7wPX/Gp1QosNmE1++8wG+j3AvznSzNy+BXbxzkEwtcQVvNcM2uamZOTGZyCM4XtizP\nyaPrDtPc3okjJvRWewwlwS6EK6XAr9OiuO82zuLk6Xb+8M5hv73OYKoaWthaWhfQFfqGY6nV9Xnz\nkbpghxLyNGkoFQHmulJZMWsCv3unhJOnAr82+au7gjcNujfOm5xGtF14T7veDkmThlIR4u7l02hu\n7+TXbx0K+GuvLq7irAlJI+4J5m+OmCjm5aZpXcMLmjSUihD545L4+Lk5PLG+lMr6lqFP8JFjja1s\nKa0LqbEZ/VmW52T30Ubqm9uDHUpI06ShVAT56qXTQODnAZw6fe3uaowhZOsZPZblZ2CMLgE7FE0a\nSkWQ7NR4blo8ib8UVXDgWGAm6XtlZxUF4xIpGJ8UkNcbqTmuVBJi7F7POhypNGkoFWG+dFE+jpgo\nfvwP/0+dXtPUxqYjtSFbAPcUbbexaGoG7+mdxqA0aSgVYdITYrjtI1NZu/sY28r828U0XJqmeizN\ny+DwidMcDWDNJ9xo0lAqAt1aOIWMhBh+6Oep01cXVzE1M4HpId401aNnQSud9XZgmjSUikAJsVHc\ncXE+G0pqz5iW3VcOHGtiQ8lJrpg9MWzWdJ8+PomMhBhtohqEJg2lItSqRbnkpMXzv2v3+nS509aO\nLn762n6ufPBdEmKj+Ldzc3x2bX+z2YQleRmsO3gi5BavChWaNJSKULFRdu786DR2VTay2lrnYrTe\n3l/D8p//iwdfP8CK2RN4/c4LmBKCc00NZlm+k+NNbRyqORXsUEKSJg2lItjKudlMH5/ET/6xf1SL\nEB1rbOXLTxVx86ObsIvw5K2LeHDVPMYlx/kw2sBYltdT19Amqv5o0lAqgtltwt3Lp3P4xGn+b0vF\nsM/v7Orm0XcPc8lP3ua1Pce486PTWPO18ym01ggJR7kZDnLS4rUYPgCdA1ipCHfpjHHMz03lF6/v\n59p52V4vK7u9vJ7vvFDM7qONXDAtkwdWzmJSRng1RQ1kWZ6TNbuq6Oo22G3hUcQPFL3TUCrCiQjf\nXHEWxxrbeGz9kSGPb2ju6F2W9sSpNh66YT5/+ux5YyZhgHvd8MbWTnZVNgQ7lJCjdxpKKRZNzeDC\n6Zn8+s2DrDovlxTHmSsHGmN4cXsl33vlfWpPt3PL0snc+dFpPltlMJQs7alrHDrBHFdqkKMJLXqn\noZQC4BvLp9PY2snD/zpz6vSDx09xw+828vVnd5CT5uDl2wv5r4/NGpMJAyAzKZbp45N4T4vhZ9A7\nDaUUALOyUrh6ThaPrjvMLUsnMy45jtaOLn71xkEe/tch4qPtfO/a2aw6LxdbBLTzL83P4KmNZbR2\ndBEX7V2dJxLonYZSqtedH51GZ5fhwTcO8Obe43z0Z2/zqzcP8rE5Wbxx94V8etGkiEgY4C6Gt3V2\nU+Tn+bnCjd5pKKV6TXYmcP1CF09uKOPJDWXkj0vk6c8vZkleRrBDC7hFU9Ox24T3Dp7srXEoTRpK\nqT6+cnEBu482cumM8Xz+/KnEREVmg0RSXDTn5KSw7tAJ7mZ6sMMJGZo0lFIfMi45jhe+tCzYYYSE\nZXlOfvP2IZpaO8Zs0X+4IvNPCKWU8sLS/Ay6ug0bS2qDHUrI0KShlFIDmJ+bRmyUjXWHdEqRHpo0\nlFJqAHHRds6bnK7jNTxo0lBKqUEszc9g37Emjje1BjuUkKBJQymlBlFoLQG7XlfzAzRpKKXUoGZl\npZAcF6VTpVs0aSil1CDsvUvAntQlYNGkoZRSQ1qW76SyvoWy2uZghxJ0mjSUUmoIS3UJ2F6aNJRS\nagh5mQmMT47V8Rr4OWmIyAoR2SciB0Xknn72/0xEtltf+0Wk3mNfl8e+l/0Zp1JKDUZEWJbnZP2h\nk3R3R3Zdw29zT4mIHXgI+ChQAWwWkZeNMXt6jjHGfN3j+DuAeR6XaDHGzPVXfEopNRxL8538dVsl\ne6ubmJmVHOxwgsafdxoLgYPGmBJjTDvwDLBykONXAU/7MR6llBqxZfnu6eHfi/AmKn8mjWyg3ON5\nhbXtDCIyCZgCvOGxOU5EtojIBhG5ZoDzbrOO2VJTU+OruJVS6gwTU+KZ6kyI+PEaoVIIvx543hjT\n5bFtkjFmAXAD8HMRyet7kjHmEWPMAmPMgszMzEDFqpSKUEvzM9h0uJaOru5ghxI0/kwalYDL43mO\nta0/19OnacoYU2l9LwHe4sP1DqWUCrhleU5Ot3exo7x+6IPHKH8mjc1AgYhMEZEY3InhjF5QInIW\nkAas99iWJiKx1mMnsAzY0/dcpZQKpCV5GYhE9ngNvyUNY0wncDuwFngfeM4Ys1tEHhCRqz0OvR54\nxnx4fP4MYIuI7ADeBH7g2etKKaWCIdURw6ysZP51oIauCO16K2NlLpUFCxaYLVu2BDsMpdQY94t/\nHuBn/9zPhOQ4Vs7L4tp52Zw1IXy74IrIVqt+7BVdI1wppYbhyxflMTUzgRe3VfKHdw7z8NslzJiY\nzHXzsrl6bhbjk+OCHaJf6Z2GUkqN0MlTbfxtx1Fe2H6UHeX12MQ9ueE1c7NZMXsCCbH++bvcGENF\nXQs7KurZUV5PfEwUd3502oiuNdw7DU0aSinlA4dqTvHStkpe2F5JeW0L8dF2Lps1nmvnZVOY7yTK\nPvISckNzR2+C2F5ez46Kek6cagcgJsrGxdPH8dvPnDuia2vSUEqpIDLGsLW0jr9uq+SVnVU0tHTg\nTIzl6jlZXDc/m1lZyYjIgOe3dXbxflXTBwmivJ6SE6d79+dlJjDXlcZcVwpzXWlMn5BETNTIE5Im\nDaWUChFtnV28ubeGF7ZV8Mbe43R0GfLHJXLtvGxWzs0iOzWewydOs6Oinu1l9WyvaOD9o420W4MH\nM5NimetK7f06OyeF5Lhon8aoSUMppUJQfXM7rxRX8eK2SjYfqQMgKTaKprZOABwxds7OTulNEHNc\nqUxMiRv0rsQXtPeUUkqFoFRHDJ9eNIlPL5pEeW0zL26rpKqxlXOyU5ibm0p+ZuKo6h6BoklDKaUC\nzJXu4I5LCoIdxoiEflpTSikVMjRpKKWU8pomDaWUUl7TpKGUUsprmjSUUkp5TZOGUkopr2nSUEop\n5TVNGkoppbw2ZqYREZEaoHQUl3ACJ3wUTiCEW7ygMQdKuMUcbvHC2Ip5kjEm09uLjJmkMVoismU4\n868EW7jFCxpzoIRbzOEWL0R2zNo8pZRSymuaNJRSSnlNk8YHHgl2AMMUbvGCxhwo4RZzuMULERyz\n1jSUUkp5Te80lFJKeU2ThlJKKa9FVNIQkRUisk9EDorIPf3sjxWRZ639G0VkcuCj/FA8LhF5U0T2\niMhuEflqP8dcKCINIrLd+rovGLH2iemIiBRb8ZyxBq+4PWi9zztFZH4w4vSIZ7rH+7ddRBpF5Gt9\njgn6+ywij4rIcRHZ5bEtXUReE5ED1ve0Ac692TrmgIjcHMR4fyQie63/9xdEJHWAcwf9DAU45vtF\npNLj//6KAc4d9PdLgGN+1iPeIyKyfYBzh/8+G2Mi4guwA4eAqUAMsAOY2eeYLwG/tR5fDzwb5Jgn\nAvOtx0nA/n5ivhD4e7Df3z4xHQGcg+y/AlgDCLAY2BjsmPt8TqpxD3gKqfcZ+AgwH9jlse1/gXus\nx/cAP+znvHSgxPqeZj1OC1K8lwFR1uMf9hevN5+hAMd8P3C3F5+bQX+/BDLmPvt/Atznq/c5ku40\nFgIHjTElxph24BlgZZ9jVgKPWY+fBy4Rf6/qPghjTJUxpsh63AS8D2QHKx4fWgk8btw2AKkiMjHY\nQVkuAQ4ZY0Yzu4BfGGP+BdT22ez5mX0MuKafU5cDrxljao0xdcBrwAq/BWrpL15jzD+MMZ3W0w1A\njr/jGI4B3mNvePP7xS8Gi9n6/fVJ4GlfvV4kJY1soNzjeQVn/gLuPcb6YDcAGQGJbghWU9k8YGM/\nu5eIyA4RWSMiswIaWP8M8A8R2Soit/Wz35v/i2C5noF/wELtfQYYb4ypsh5XA+P7OSZU3+/P4b7j\n7M9Qn6FAu91qUnt0gCbAUH2PzweOGWMODLB/2O9zJCWNsCUiicBfgK8ZYxr77C7C3ZQyB/gl8GKg\n4+tHoTFmPnA58GUR+UiwA/KGiMQAVwP/18/uUHyfP8S42xvCog+9iHwH6AT+PMAhofQZ+g2QB8wF\nqnA394SLVQx+lzHs9zmSkkYl4PJ4nmNt6/cYEYkCUoCTAYluACISjTth/NkY89e++40xjcaYU9bj\n1UC0iDgDHGbfmCqt78eBF3Dfunvy5v8iGC4Hiowxx/ruCMX32XKsp2nP+n68n2NC6v0WkVuAq4BP\nW4nuDF58hgLGGHPMGNNljOkGfjdALCH1HkPv77DrgGcHOmYk73MkJY3NQIGITLH+orweeLnPMS8D\nPT1LPg68MdCHOhCs9sg/AO8bY346wDETeuouIrIQ9/9p0BKdiCSISFLPY9yFz119DnsZuMnqRbUY\naPBoYgmmAf8qC7X32YPnZ/Zm4KV+jlkLXCYiaVbTymXWtoATkRXAfwBXG2OaBzjGm89QwPSpt107\nQCze/H4JtEuBvcaYiv52jvh9DkR1P1S+cPfa2Y+7l8N3rG0P4P4AA8Thbpo4CGwCpgY53kLczQ07\nge3W1xXAF4AvWMfcDuzG3VtjA7A0yDFPtWLZYcXV8z57xizAQ9b/QzGwIAQ+Gwm4k0CKx7aQep9x\nJ7QqoAN3m/mtuGturwMHgH8C6daxC4Dfe5z7OetzfRD4bBDjPYi77b/n89zTWzELWD3YZyiIMT9h\nfU534k4EE/vGbD0/4/dLsGK2tv+p5/Prceyo32edRkQppZTXIql5Siml1Chp0lBKKeU1TRpKKaW8\npklDKaWU1zRpKKWU8pomDaWGICJdfWbB9dkMpiIy2XN2UqVCXVSwA1AqDLQYY+YGOwilQoHeaSg1\nQtZaBP9rrUewSUTyre2TReQNa4K710Uk19o+3lpDYof1tdS6lF1EfifuNVP+ISLx1vFfEfdaKjtF\n5Jkg/TOV+hBNGkoNLb5P89SnPPY1GGPOBn4F/Nza9kvgMWPMObgn5HvQ2v4g8LZxT3o4H/coXIAC\n4CFjzCygHvg3a/s9wDzrOl/w1z9OqeHQEeFKDUFEThljEvvZfgS42BhTYk0sWW2MyRCRE7inmuiw\ntlcZY5wiUgPkGGPaPK4xGfdaFwXW828C0caY74rIq8Ap3DPqvmisCROVCia901BqdMwAj4ejzeNx\nFx/UGq/EPUfXfGCzNWupUkGlSUOp0fmUx/f11uP3cM9yCvBp4B3r8evAFwFExC4iKQNdVERsgMsY\n8ybwTdzT9J9xt6NUoOlfLkoNLV5Etns8f9UY09PtNk1EduK+W1hlbbsD+KOIfAOoAT5rbf8q8IiI\n3Ir7juKLuGcn7Y8deNJKLAI8aIyp99m/SKkR0pqGUiNk1TQWGGNOBDsWpQJFm6eUUkp5Te80lFJK\neU3vNJRSSnlNk4ZSSimvadJQSinlNU0aSimlvKZJQymllNf+P+Fxw9x9ket2AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H1jtFAVD4Wuj",
        "colab_type": "code",
        "outputId": "dc625bd1-94ee-4cfe-8c47-9ac2d984bc17",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        }
      },
      "source": [
        "plot_metrics_json(metric_file, metric_name='dice', n_epochs=18)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAEGCAYAAACZ0MnKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Qh2LREI4bjx",
        "colab_type": "code",
        "outputId": "64d2d486-9af2-4f0d-8991-8ef01e98daae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        }
      },
      "source": [
        "plot_metrics_json(metric_file, metric_name='_base/lr', n_epochs=18)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZQAAAEGCAYAAABCa2PoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nfzSvEgcSrfWdAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CbieS0yi5-GV",
        "colab_type": "text"
      },
      "source": [
        "# Load the Model and Make Inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F1CDQO6nJ7Lm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Step 1. Load the trained model\n",
        "logdir = '/content/gdrive/My Drive/kaggle_cloud/log_inceptionresnetv2/'\n",
        "path_to_checkpoint = os.path.join(logdir, 'checkpoints/best_full.pth')\n",
        "checkpoint = torch.load(path_to_checkpoint)\n",
        "\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "runner = SupervisedRunner(model=model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pE3KQr1LM-7L",
        "colab_type": "code",
        "outputId": "f4a4118b-e5eb-42a5-93fa-6a7fb3a45d32",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "checkpoint.keys()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['epoch_metrics', 'valid_metrics', 'stage', 'epoch', 'checkpoint_data', 'model_state_dict', 'criterion_state_dict', 'optimizer_state_dict', 'scheduler_state_dict'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dKJ_fCWh71KP",
        "colab_type": "code",
        "outputId": "a70ce0d6-2b08-4e7e-904e-d1c31da39e81",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Step 3. Make predictions\n",
        "import gc\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "25122"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PKdI_N9O7w55",
        "colab_type": "code",
        "outputId": "82e2838d-ab06-4ad1-e38a-27defc1f3d8b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "# Step 2. Select the \"best parameters\"\n",
        "encoded_pixels = []\n",
        "loaders = {\"infer\": valid_loader}\n",
        "runner.infer(\n",
        "    model=model,\n",
        "    loaders=loaders,\n",
        "    callbacks=[\n",
        "        CheckpointCallback(\n",
        "            resume=f\"{logdir}/checkpoints/best.pth\"),\n",
        "        InferCallback()\n",
        "    ],\n",
        ")\n",
        "valid_masks = []\n",
        "probabilities = np.zeros((2220, 350, 525))\n",
        "for i, (batch, output) in enumerate(tqdm.tqdm(zip(\n",
        "        valid_dataset, runner.callbacks[0].predictions[\"logits\"]))):\n",
        "    image, mask = batch\n",
        "    for m in mask:\n",
        "        if m.shape != (350, 525):\n",
        "            m = cv2.resize(m, dsize=(525, 350), interpolation=cv2.INTER_LINEAR)\n",
        "        valid_masks.append(m)\n",
        "\n",
        "    for j, probability in enumerate(output):\n",
        "        if probability.shape != (350, 525):\n",
        "            probability = cv2.resize(probability, dsize=(525, 350), interpolation=cv2.INTER_LINEAR)\n",
        "        probabilities[i * 4 + j, :, :] = probability"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "=> loading checkpoint /content/gdrive/My Drive/kaggle_cloud/run_log1109/checkpoints/best.pth\n",
            "loaded checkpoint /content/gdrive/My Drive/kaggle_cloud/run_log1109/checkpoints/best.pth (epoch 19)\n",
            "Top best models:\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "555it [01:09,  7.94it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ooerVvkBkFF",
        "colab_type": "code",
        "outputId": "abbc93d6-adf4-461e-9c34-c82f29e9c2a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 504
        }
      },
      "source": [
        "# For each class, find a best parameter ('threshold' and 'size')\n",
        "class_params = {}\n",
        "for class_id in range(4):\n",
        "    print(class_id)\n",
        "    attempts = []\n",
        "    for t in range(0, 100, 5):\n",
        "        t /= 100\n",
        "        for ms in [0, 100, 1200, 5000, 10000]:\n",
        "            masks = []\n",
        "            for i in range(class_id, len(probabilities), 4):\n",
        "                probability = probabilities[i]\n",
        "                predict, num_predict = post_process(sigmoid(probability), t, ms)\n",
        "                masks.append(predict)\n",
        "\n",
        "            d = []\n",
        "            for i, j in zip(masks, valid_masks[class_id::4]):\n",
        "                if (i.sum() == 0) & (j.sum() == 0):\n",
        "                    d.append(1)\n",
        "                else:\n",
        "                    d.append(dice(i, j))\n",
        "\n",
        "            attempts.append((t, ms, np.mean(d)))\n",
        "\n",
        "    attempts_df = pd.DataFrame(attempts, columns=['threshold', 'size', 'dice'])\n",
        "\n",
        "\n",
        "    attempts_df = attempts_df.sort_values('dice', ascending=False)\n",
        "    print(attempts_df.head())\n",
        "    best_threshold = attempts_df['threshold'].values[0]\n",
        "    best_size = attempts_df['size'].values[0]\n",
        "    \n",
        "    class_params[class_id] = (best_threshold, best_size)\n",
        "\n",
        "print(class_params)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "    threshold   size      dice\n",
            "64       0.60  10000  0.617677\n",
            "59       0.55  10000  0.614424\n",
            "44       0.40  10000  0.611265\n",
            "69       0.65  10000  0.609774\n",
            "54       0.50  10000  0.609170\n",
            "1\n",
            "    threshold   size      dice\n",
            "39       0.35  10000  0.760165\n",
            "53       0.50   5000  0.760070\n",
            "44       0.40  10000  0.759396\n",
            "59       0.55  10000  0.759296\n",
            "48       0.45   5000  0.758921\n",
            "2\n",
            "    threshold   size      dice\n",
            "74       0.70  10000  0.601254\n",
            "59       0.55  10000  0.600889\n",
            "69       0.65  10000  0.599362\n",
            "64       0.60  10000  0.598662\n",
            "79       0.75  10000  0.597799\n",
            "3\n",
            "    threshold   size      dice\n",
            "54       0.50  10000  0.621536\n",
            "59       0.55  10000  0.618383\n",
            "49       0.45  10000  0.615997\n",
            "64       0.60  10000  0.614372\n",
            "63       0.60   5000  0.614245\n",
            "{0: (0.6, 10000), 1: (0.35, 10000), 2: (0.7, 10000), 3: (0.5, 10000)}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OfsJwqb774yw",
        "colab_type": "code",
        "outputId": "693ec180-341e-4a89-f890-89491c9d9322",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        }
      },
      "source": [
        "test_dataset = CloudDataset(df=sub, datatype='test', img_ids=test_ids, transforms = get_validation_augmentation(), preprocessing=get_preprocessing(preprocessing_fn))\n",
        "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False, num_workers=0)\n",
        "\n",
        "loaders = {\"test\": test_loader}\n",
        "\n",
        "encoded_pixels = []\n",
        "image_id = 0\n",
        "for i, test_batch in enumerate(tqdm.tqdm(loaders['test'])):\n",
        "    runner_out = runner.predict_batch({\"features\": test_batch[0].cuda()})['logits']\n",
        "    for i, batch in enumerate(runner_out):\n",
        "        for probability in batch:\n",
        "            \n",
        "            probability = probability.cpu().detach().numpy()\n",
        "            if probability.shape != (350, 525):\n",
        "                probability = cv2.resize(probability, dsize=(525, 350), interpolation=cv2.INTER_LINEAR)\n",
        "            predict, num_predict = post_process(sigmoid(probability), class_params[image_id % 4][0], class_params[image_id % 4][1])\n",
        "            if num_predict == 0:\n",
        "                encoded_pixels.append('')\n",
        "            else:\n",
        "                r = mask2rle(predict)\n",
        "                encoded_pixels.append(r)\n",
        "            image_id += 1\n",
        "\n",
        "sub['EncodedPixels'] = encoded_pixels\n",
        "sub.to_csv(os.path.join(logdir, 'submission.csv'), columns=['Image_Label', 'EncodedPixels'], index=False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/albumentations/augmentations/transforms.py:2247: UserWarning:\n",
            "\n",
            "Using lambda is incompatible with multiprocessing. Consider using regular functions or partial().\n",
            "\n",
            " 24%|██▍       | 113/463 [10:00<26:13,  4.50s/it]/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:148: RuntimeWarning:\n",
            "\n",
            "overflow encountered in exp\n",
            "\n",
            "100%|██████████| 463/463 [36:33<00:00,  4.74s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y4MDm23qf1Go",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}